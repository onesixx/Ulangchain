{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Create a FAISS VectorStore\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison worked at kensho\"], embedding=OpenAIEmbeddings() # deployment=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "# Create a Retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Create a prompt, model\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI() # model_name='gpt-3.5-turbo'\n",
    "\n",
    "# Chaining a pipeline\n",
    "retrieval_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run retrieva_chain\n",
    "retrieval_chain.invoke(\"where did harrison work?\")\n",
    "# 'Harrison worked at Kensho.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is the framework for building context-aware reasoning applications'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vector store with a sample text\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.3\", base_url=\"172.17.0.2:11434\")\n",
    "\n",
    "text = \"LangChain is the framework for building context-aware reasoning applications\"\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [text],\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "# Use the vectorstore as a retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Retrieve the most similar text\n",
    "retrieved_documents = retriever.invoke(\"What is LangChain?\")\n",
    "\n",
    "# show the retrieved document's content\n",
    "retrieved_documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='bb8ecfce-8fe7-4b1b-bce7-e7f34a58f046', metadata={}, page_content='LangChain is the framework for building context-aware reasoning applications')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Hello?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Question: {question}\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"question\": \"Who lived longer, Muhammad Ali or Alan Turing?\",\n",
    "        \"answer\": \"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: How old was Muhammad Ali when he died?\n",
    "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
    "Follow up: How old was Alan Turing when he died?\n",
    "Intermediate answer: Alan Turing was 41 years old when he died.\n",
    "So the final answer is: Muhammad Ali\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"When was the founder of craigslist born?\",\n",
    "        \"answer\": \"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the founder of craigslist?\n",
    "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
    "Follow up: When was Craig Newmark born?\n",
    "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
    "So the final answer is: December 6, 1952\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who was the maternal grandfather of George Washington?\",\n",
    "        \"answer\": \"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the mother of George Washington?\n",
    "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
    "Follow up: Who was the father of Mary Ball Washington?\n",
    "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
    "So the final answer is: Joseph Ball\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Are both the directors of Jaws and Casino Royale from the same country?\",\n",
    "        \"answer\": \"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who is the director of Jaws?\n",
    "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
    "Follow up: Where is Steven Spielberg from?\n",
    "Intermediate Answer: The United States.\n",
    "Follow up: Who is the director of Casino Royale?\n",
    "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
    "Follow up: Where is Martin Campbell from?\n",
    "Intermediate Answer: New Zealand.\n",
    "So the final answer is: No\n",
    "\"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How old was Muhammad Ali when he died?\n",
      "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
      "Follow up: How old was Alan Turing when he died?\n",
      "Intermediate answer: Alan Turing was 41 years old when he died.\n",
      "So the final answer is: Muhammad Ali\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(example_prompt.invoke(examples[0]).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How old was Muhammad Ali when he died?\n",
      "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
      "Follow up: How old was Alan Turing when he died?\n",
      "Intermediate answer: Alan Turing was 41 years old when he died.\n",
      "So the final answer is: Muhammad Ali\n",
      "\n",
      "\n",
      "Question: When was the founder of craigslist born?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the founder of craigslist?\n",
      "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
      "Follow up: When was Craig Newmark born?\n",
      "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
      "So the final answer is: December 6, 1952\n",
      "\n",
      "\n",
      "Question: Who was the maternal grandfather of George Washington?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the mother of George Washington?\n",
      "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
      "Follow up: Who was the father of Mary Ball Washington?\n",
      "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
      "So the final answer is: Joseph Ball\n",
      "\n",
      "\n",
      "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who is the director of Jaws?\n",
      "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
      "Follow up: Where is Steven Spielberg from?\n",
      "Intermediate Answer: The United States.\n",
      "Follow up: Who is the director of Casino Royale?\n",
      "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
      "Follow up: Where is Martin Campbell from?\n",
      "Intermediate Answer: New Zealand.\n",
      "So the final answer is: No\n",
      "\n",
      "\n",
      "Question: Who was the father of Mary Ball Washington?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question: {input}\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "print(\n",
    "    prompt.invoke({\"input\": \"Who was the father of Mary Ball Washington?\"}).to_string()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples most similar to the input: Who was the father of Mary Ball Washington?\n",
      "\n",
      "\n",
      "question: Who was the maternal grandfather of George Washington?\n",
      "answer: \n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the mother of George Washington?\n",
      "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
      "Follow up: Who was the father of Mary Ball Washington?\n",
      "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
      "So the final answer is: Joseph Ball\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # This is the list of examples available to select from.\n",
    "    examples,\n",
    "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    OllamaEmbeddings(model=\"llama3.3\", base_url=\"172.17.0.2:11434\"),\n",
    "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    FAISS,\n",
    "    # This is the number of examples to produce.\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "# Select the most similar example to the input.\n",
    "question = \"Who was the father of Mary Ball Washington?\"\n",
    "selected_examples = example_selector.select_examples({\"question\": question})\n",
    "print(f\"Examples most similar to the input: {question}\")\n",
    "for example in selected_examples:\n",
    "    print(\"\\n\")\n",
    "    for k, v in example.items():\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was the maternal grandfather of George Washington?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the mother of George Washington?\n",
      "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
      "Follow up: Who was the father of Mary Ball Washington?\n",
      "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
      "So the final answer is: Joseph Ball\n",
      "\n",
      "\n",
      "Question: Who was the father of Mary Ball Washington?\n"
     ]
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question: {input}\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "print(\n",
    "    prompt.invoke({\"input\": \"Who was the father of Mary Ball Washington?\"}).to_string()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"llama3.3\", model_provider=\"ollama\", base_url=\"172.17.0.2:11434\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao!', additional_kwargs={}, response_metadata={'model': 'llama3.3', 'created_at': '2025-03-14T01:01:40.691581102Z', 'done': True, 'done_reason': 'stop', 'total_duration': 13545661952, 'load_duration': 13184839170, 'prompt_eval_count': 24, 'prompt_eval_duration': 159648000, 'eval_count': 4, 'eval_duration': 155859000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-dbcd79b5-37e7-4f6c-beb2-1764011feb09-0', usage_metadata={'input_tokens': 24, 'output_tokens': 4, 'total_tokens': 28})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕!! 어떻게 지내고 있어?', additional_kwargs={}, response_metadata={'model': 'llama3.3', 'created_at': '2025-03-14T01:04:03.126799172Z', 'done': True, 'done_reason': 'stop', 'total_duration': 755716457, 'load_duration': 21647917, 'prompt_eval_count': 29, 'prompt_eval_duration': 108504000, 'eval_count': 10, 'eval_duration': 495500000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-43b006f9-a038-46bf-b6b7-5c4fcb47c04c-0', usage_metadata={'input_tokens': 29, 'output_tokens': 10, 'total_tokens': 39})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([\n",
    "    {\"role\": \"system\", \"content\": \"Translate the following from English into Korean, very friendly like friend.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello\"}\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕!!"
     ]
    }
   ],
   "source": [
    "for token in model.stream([\n",
    "    {\"role\": \"system\", \"content\": \"Translate the following from English into Korean, very friendly like friend.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello\"}\n",
    "    ]):\n",
    "    print(token.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C|iao|!||"
     ]
    }
   ],
   "source": [
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\"language\": \"Korean\", \"text\": \"hi!\"})\n",
    "\n",
    "prompt\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"./manual.md\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(documents)\n",
    "\n",
    "len(all_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated vectors of length 8192\n",
      "\n",
      "[0.002270376, -0.0002960831, -0.0005981432, 0.0067523727, -0.0017729027, -0.008718284, -0.010643234, -0.00091156556, 0.00011833437, -0.01181567]\n"
     ]
    }
   ],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"llama3.3\", base_url=\"172.17.0.2:11434\")\n",
    "v1 = embeddings.embed_query(all_splits[0].page_content)\n",
    "v2 = embeddings.embed_query(all_splits[1].page_content)\n",
    "assert len(v1) == len(v2)\n",
    "print(f\"Generated vectors of length {len(v1)}\\n\")\n",
    "print(v1[:10])\n",
    "\n",
    "# text = \"LangChain is the framework for building context-aware reasoning applications\"\n",
    "\n",
    "# vectorstore = FAISS.from_texts(\n",
    "#     [text],\n",
    "#     embedding=embeddings,\n",
    "# )\n",
    "\n",
    "# # Use the vectorstore as a retriever\n",
    "# retriever = vectorstore.as_retriever()\n",
    "\n",
    "# # Retrieve the most similar text\n",
    "# retrieved_documents = retriever.invoke(\"What is LangChain?\")\n",
    "\n",
    "# # show the retrieved document's content\n",
    "# retrieved_documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "vectorstore = FAISS(embedding_function=embeddings, index=index, docstore=InMemoryDocstore(), index_to_docstore_id={})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fc4aa937-32c9-4665-9b93-b24db2031bb4',\n",
       " '4557935f-7586-4e1d-bfd3-d106dcd7a389',\n",
       " 'b5ec9ad0-8a82-4147-a007-2f64547077e4',\n",
       " '9b304f47-3c9e-42b4-90c2-431705ff4d60',\n",
       " 'a9ebfa69-68ea-4f72-96f2-dd948929072a',\n",
       " '8c17ee95-628f-4df6-8220-d8d7ae7affeb',\n",
       " '67bbb46f-25ba-415b-857e-008b55f55a55',\n",
       " '20539fa1-9e52-498d-a914-a89aaac4cc56',\n",
       " '1baf27e7-05df-45c7-a23d-39ec82d4c14a',\n",
       " '58bdaef0-9e18-46b3-8e54-68abf56fa9ae']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vectorstore.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
      "* I have a bad feeling I am going to get deleted :( [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "results = vectorstore.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=2,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.553510] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news'}]\n"
     ]
    }
   ],
   "source": [
    "results = vectorstore.similarity_search_with_score(\n",
    "    \"Will it be hot tomorrow?\", k=1, filter={\"source\": \"news\"}\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1baf27e7-05df-45c7-a23d-39ec82d4c14a', metadata={'source': 'news'}, page_content='The stock market is down 500 points today due to fears of a recession.')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 1})\n",
    "retriever.invoke(\"Stealing from the bank is a crime\", filter={\"source\": \"news\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vector_store = FAISS.load_local(\n",
    "    \"faiss_index\", embeddings, allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "RANDOM_SEED = 42  # 재현성을 위한 고정된 시드 값\n",
    "\n",
    "### --- 위의 인용된 코드에서 주석과 문서화를 추가함 --- ###\n",
    "\n",
    "\n",
    "def global_cluster_embeddings(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    n_neighbors: Optional[int] = None,\n",
    "    metric: str = \"cosine\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    UMAP을 사용하여 임베딩의 전역 차원 축소를 수행합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로 된 입력 임베딩.\n",
    "    - dim: 축소된 공간의 목표 차원.\n",
    "    - n_neighbors: 선택 사항; 각 점을 고려할 이웃의 수.\n",
    "                   제공되지 않으면 임베딩 수의 제곱근으로 기본 설정됩니다.\n",
    "    - metric: UMAP에 사용할 거리 측정 기준.\n",
    "\n",
    "    반환값:\n",
    "    - 지정된 차원으로 축소된 임베딩의 numpy 배열.\n",
    "    \"\"\"\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int((len(embeddings) - 1) ** 0.5)\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=n_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_cluster_embeddings(\n",
    "    embeddings: np.ndarray, dim: int, num_neighbors: int = 10, metric: str = \"cosine\"\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    임베딩에 대해 지역 차원 축소를 수행합니다. 이는 일반적으로 전역 클러스터링 이후에 사용됩니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로서의 입력 임베딩.\n",
    "    - dim: 축소된 공간의 목표 차원 수.\n",
    "    - num_neighbors: 각 점에 대해 고려할 이웃의 수.\n",
    "    - metric: UMAP에 사용할 거리 측정 기준.\n",
    "\n",
    "    반환값:\n",
    "    - 지정된 차원으로 축소된 임베딩의 numpy 배열.\n",
    "    \"\"\"\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=num_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_clusters(\n",
    "    embeddings: np.ndarray, max_clusters: int = 50, random_state: int = RANDOM_SEED\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    가우시안 혼합 모델(Gaussian Mixture Model)을 사용하여 베이지안 정보 기준(BIC)을 통해 최적의 클러스터 수를 결정합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로서의 입력 임베딩.\n",
    "    - max_clusters: 고려할 최대 클러스터 수.\n",
    "    - random_state: 재현성을 위한 시드.\n",
    "\n",
    "    반환값:\n",
    "    - 발견된 최적의 클러스터 수를 나타내는 정수.\n",
    "    \"\"\"\n",
    "    max_clusters = min(\n",
    "        max_clusters, len(embeddings)\n",
    "    )  # 최대 클러스터 수와 임베딩의 길이 중 작은 값을 최대 클러스터 수로 설정\n",
    "    n_clusters = np.arange(1, max_clusters)  # 1부터 최대 클러스터 수까지의 범위를 생성\n",
    "    bics = []  # BIC 점수를 저장할 리스트\n",
    "    for n in n_clusters:  # 각 클러스터 수에 대해 반복\n",
    "        gm = GaussianMixture(\n",
    "            n_components=n, random_state=random_state\n",
    "        )  # 가우시안 혼합 모델 초기화\n",
    "        gm.fit(embeddings)  # 임베딩에 대해 모델 학습\n",
    "        bics.append(gm.bic(embeddings))  # 학습된 모델의 BIC 점수를 리스트에 추가\n",
    "    return n_clusters[np.argmin(bics)]  # BIC 점수가 가장 낮은 클러스터 수를 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_cluster(embeddings: np.ndarray, threshold: float, random_state: int = 0):\n",
    "    \"\"\"\n",
    "    확률 임계값을 기반으로 가우시안 혼합 모델(GMM)을 사용하여 임베딩을 클러스터링합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로서의 입력 임베딩.\n",
    "    - threshold: 임베딩을 클러스터에 할당하기 위한 확률 임계값.\n",
    "    - random_state: 재현성을 위한 시드.\n",
    "\n",
    "    반환값:\n",
    "    - 클러스터 레이블과 결정된 클러스터 수를 포함하는 튜플.\n",
    "    \"\"\"\n",
    "    n_clusters = get_optimal_clusters(embeddings)  # 최적의 클러스터 수를 구합니다.\n",
    "    # 가우시안 혼합 모델을 초기화합니다.\n",
    "    gm = GaussianMixture(n_components=n_clusters, random_state=random_state)\n",
    "    gm.fit(embeddings)  # 임베딩에 대해 모델을 학습합니다.\n",
    "    probs = gm.predict_proba(\n",
    "        embeddings\n",
    "    )  # 임베딩이 각 클러스터에 속할 확률을 예측합니다.\n",
    "    # 임계값을 초과하는 확률을 가진 클러스터를 레이블로 선택합니다.\n",
    "    labels = [np.where(prob > threshold)[0] for prob in probs]\n",
    "    return labels, n_clusters  # 레이블과 클러스터 수를 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    threshold: float,\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    임베딩에 대해 차원 축소, 가우시안 혼합 모델을 사용한 클러스터링, 각 글로벌 클러스터 내에서의 로컬 클러스터링을 순서대로 수행합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로 된 입력 임베딩입니다.\n",
    "    - dim: UMAP 축소를 위한 목표 차원입니다.\n",
    "    - threshold: GMM에서 임베딩을 클러스터에 할당하기 위한 확률 임계값입니다.\n",
    "\n",
    "    반환값:\n",
    "    - 각 임베딩의 클러스터 ID를 포함하는 numpy 배열의 리스트입니다.\n",
    "    \"\"\"\n",
    "    if len(embeddings) <= dim + 1:\n",
    "        # 데이터가 충분하지 않을 때 클러스터링을 피합니다.\n",
    "        return [np.array([0]) for _ in range(len(embeddings))]\n",
    "\n",
    "    # 글로벌 차원 축소\n",
    "    reduced_embeddings_global = global_cluster_embeddings(embeddings, dim)\n",
    "    # 글로벌 클러스터링\n",
    "    global_clusters, n_global_clusters = GMM_cluster(\n",
    "        reduced_embeddings_global, threshold\n",
    "    )\n",
    "\n",
    "    all_local_clusters = [np.array([]) for _ in range(len(embeddings))]\n",
    "    total_clusters = 0\n",
    "\n",
    "    # 각 글로벌 클러스터를 순회하며 로컬 클러스터링 수행\n",
    "    for i in range(n_global_clusters):\n",
    "        # 현재 글로벌 클러스터에 속하는 임베딩 추출\n",
    "        global_cluster_embeddings_ = embeddings[\n",
    "            np.array([i in gc for gc in global_clusters])\n",
    "        ]\n",
    "\n",
    "        if len(global_cluster_embeddings_) == 0:\n",
    "            continue\n",
    "        if len(global_cluster_embeddings_) <= dim + 1:\n",
    "            # 작은 클러스터는 직접 할당으로 처리\n",
    "            local_clusters = [np.array([0]) for _ in global_cluster_embeddings_]\n",
    "            n_local_clusters = 1\n",
    "        else:\n",
    "            # 로컬 차원 축소 및 클러스터링\n",
    "            reduced_embeddings_local = local_cluster_embeddings(\n",
    "                global_cluster_embeddings_, dim\n",
    "            )\n",
    "            local_clusters, n_local_clusters = GMM_cluster(\n",
    "                reduced_embeddings_local, threshold\n",
    "            )\n",
    "\n",
    "        # 로컬 클러스터 ID 할당, 이미 처리된 총 클러스터 수를 조정\n",
    "        for j in range(n_local_clusters):\n",
    "            local_cluster_embeddings_ = global_cluster_embeddings_[\n",
    "                np.array([j in lc for lc in local_clusters])\n",
    "            ]\n",
    "            indices = np.where(\n",
    "                (embeddings == local_cluster_embeddings_[:, None]).all(-1)\n",
    "            )[1]\n",
    "            for idx in indices:\n",
    "                all_local_clusters[idx] = np.append(\n",
    "                    all_local_clusters[idx], j + total_clusters\n",
    "                )\n",
    "\n",
    "        total_clusters += n_local_clusters\n",
    "\n",
    "    return all_local_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(texts):\n",
    "    # 텍스트 문서 목록에 대한 임베딩을 생성합니다.\n",
    "    #\n",
    "    # 이 함수는 `embd` 객체가 존재한다고 가정하며, 이 객체는 텍스트 목록을 받아 그 임베딩을 반환하는 `embed_documents` 메소드를 가지고 있습니다.\n",
    "    #\n",
    "    # 매개변수:\n",
    "    # - texts: List[str], 임베딩할 텍스트 문서의 목록입니다.\n",
    "    #\n",
    "    # 반환값:\n",
    "    # - numpy.ndarray: 주어진 텍스트 문서들에 대한 임베딩 배열입니다.\n",
    "    text_embeddings = embeddings.embed_documents(\n",
    "        texts\n",
    "    )  # 텍스트 문서들의 임베딩을 생성합니다.\n",
    "    text_embeddings_np = np.array(text_embeddings)  # 임베딩을 numpy 배열로 변환합니다.\n",
    "    return text_embeddings_np  # 임베딩된 numpy 배열을 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_cluster_texts(texts):\n",
    "    \"\"\"\n",
    "    텍스트 목록을 임베딩하고 클러스터링하여, 텍스트, 그들의 임베딩, 그리고 클러스터 라벨이 포함된 DataFrame을 반환합니다.\n",
    "\n",
    "    이 함수는 임베딩 생성과 클러스터링을 단일 단계로 결합합니다. 임베딩에 대해 클러스터링을 수행하는 `perform_clustering` 함수의 사전 정의된 존재를 가정합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - texts: List[str], 처리될 텍스트 문서의 목록입니다.\n",
    "\n",
    "    반환값:\n",
    "    - pandas.DataFrame: 원본 텍스트, 그들의 임베딩, 그리고 할당된 클러스터 라벨이 포함된 DataFrame입니다.\n",
    "    \"\"\"\n",
    "    text_embeddings_np = embed(texts)  # 임베딩 생성\n",
    "    cluster_labels = perform_clustering(\n",
    "        text_embeddings_np, 10, 0.1\n",
    "    )  # 임베딩에 대해 클러스터링 수행\n",
    "    df = pd.DataFrame()  # 결과를 저장할 DataFrame 초기화\n",
    "    df[\"text\"] = texts  # 원본 텍스트 저장\n",
    "    df[\"embd\"] = list(text_embeddings_np)  # DataFrame에 리스트로 임베딩 저장\n",
    "    df[\"cluster\"] = cluster_labels  # 클러스터 라벨 저장\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_txt(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    DataFrame에 있는 텍스트 문서를 단일 문자열로 포맷합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - df: 'text' 열에 포맷할 텍스트 문서가 포함된 DataFrame.\n",
    "\n",
    "    반환값:\n",
    "    - 모든 텍스트 문서가 특정 구분자로 결합된 단일 문자열.\n",
    "    \"\"\"\n",
    "    unique_txt = df[\"text\"].tolist()  # 'text' 열의 모든 텍스트를 리스트로 변환\n",
    "    return \"--- --- \\n --- --- \".join(\n",
    "        unique_txt\n",
    "    )  # 텍스트 문서들을 특정 구분자로 결합하여 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_cluster_summarize_texts(\n",
    "    texts: List[str], level: int\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    텍스트 목록에 대해 임베딩, 클러스터링 및 요약을 수행합니다. 이 함수는 먼저 텍스트에 대한 임베딩을 생성하고,\n",
    "    유사성을 기반으로 클러스터링을 수행한 다음, 클러스터 할당을 확장하여 처리를 용이하게 하고 각 클러스터 내의 내용을 요약합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - texts: 처리할 텍스트 문서 목록입니다.\n",
    "    - level: 처리의 깊이나 세부 사항을 정의할 수 있는 정수 매개변수입니다.\n",
    "\n",
    "    반환값:\n",
    "    - 두 개의 데이터프레임을 포함하는 튜플:\n",
    "      1. 첫 번째 데이터프레임(`df_clusters`)은 원본 텍스트, 그들의 임베딩, 그리고 클러스터 할당을 포함합니다.\n",
    "      2. 두 번째 데이터프레임(`df_summary`)은 각 클러스터에 대한 요약, 지정된 세부 수준, 그리고 클러스터 식별자를 포함합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    # 텍스트를 임베딩하고 클러스터링하여 'text', 'embd', 'cluster' 열이 있는 데이터프레임을 생성합니다.\n",
    "    df_clusters = embed_cluster_texts(texts)\n",
    "\n",
    "    # 클러스터를 쉽게 조작하기 위해 데이터프레임을 확장할 준비를 합니다.\n",
    "    expanded_list = []\n",
    "\n",
    "    # 데이터프레임 항목을 문서-클러스터 쌍으로 확장하여 처리를 간단하게 합니다.\n",
    "    for index, row in df_clusters.iterrows():\n",
    "        for cluster in row[\"cluster\"]:\n",
    "            expanded_list.append(\n",
    "                {\"text\": row[\"text\"], \"embd\": row[\"embd\"], \"cluster\": cluster}\n",
    "            )\n",
    "\n",
    "    # 확장된 목록에서 새 데이터프레임을 생성합니다.\n",
    "    expanded_df = pd.DataFrame(expanded_list)\n",
    "\n",
    "    # 처리를 위해 고유한 클러스터 식별자를 검색합니다.\n",
    "    all_clusters = expanded_df[\"cluster\"].unique()\n",
    "\n",
    "    print(f\"--Generated {len(all_clusters)} clusters--\")\n",
    "\n",
    "    # 요약\n",
    "    template = \"\"\"여기 LangChain 표현 언어 문서의 하위 집합이 있습니다.\n",
    "\n",
    "    LangChain 표현 언어는 LangChain에서 체인을 구성하는 방법을 제공합니다.\n",
    "\n",
    "    제공된 문서의 자세한 요약을 제공하십시오.\n",
    "\n",
    "    문서:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    # 각 클러스터 내의 텍스트를 요약을 위해 포맷팅합니다.\n",
    "    summaries = []\n",
    "    for i in all_clusters:\n",
    "        df_cluster = expanded_df[expanded_df[\"cluster\"] == i]\n",
    "        formatted_txt = fmt_txt(df_cluster)\n",
    "        summaries.append(chain.invoke({\"context\": formatted_txt}))\n",
    "\n",
    "    # 요약, 해당 클러스터 및 레벨을 저장할 데이터프레임을 생성합니다.\n",
    "    df_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"summaries\": summaries,\n",
    "            \"level\": [level] * len(summaries),\n",
    "            \"cluster\": list(all_clusters),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df_clusters, df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_embed_cluster_summarize(\n",
    "    texts: List[str], level: int = 1, n_levels: int = 3\n",
    ") -> Dict[int, Tuple[pd.DataFrame, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    지정된 레벨까지 또는 고유 클러스터의 수가 1이 될 때까지 텍스트를 재귀적으로 임베딩, 클러스터링, 요약하여\n",
    "    각 레벨에서의 결과를 저장합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - texts: List[str], 처리할 텍스트들.\n",
    "    - level: int, 현재 재귀 레벨 (1에서 시작).\n",
    "    - n_levels: int, 재귀의 최대 깊이.\n",
    "\n",
    "    반환값:\n",
    "    - Dict[int, Tuple[pd.DataFrame, pd.DataFrame]], 재귀 레벨을 키로 하고 해당 레벨에서의 클러스터 DataFrame과 요약 DataFrame을 포함하는 튜플을 값으로 하는 사전.\n",
    "    \"\"\"\n",
    "    results = {}  # 각 레벨에서의 결과를 저장할 사전\n",
    "\n",
    "    # 현재 레벨에 대해 임베딩, 클러스터링, 요약 수행\n",
    "    df_clusters, df_summary = embed_cluster_summarize_texts(texts, level)\n",
    "\n",
    "    # 현재 레벨의 결과 저장\n",
    "    results[level] = (df_clusters, df_summary)\n",
    "\n",
    "    # 추가 재귀가 가능하고 의미가 있는지 결정\n",
    "    unique_clusters = df_summary[\"cluster\"].nunique()\n",
    "    if level < n_levels and unique_clusters > 1:\n",
    "        # 다음 레벨의 재귀 입력 텍스트로 요약 사용\n",
    "        new_texts = df_summary[\"summaries\"].tolist()\n",
    "        next_level_results = recursive_embed_cluster_summarize(\n",
    "            new_texts, level + 1, n_levels\n",
    "        )\n",
    "\n",
    "        # 다음 레벨의 결과를 현재 결과 사전에 병합\n",
    "        results.update(next_level_results)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"./manual.md\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_texts = [d.page_content for d in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# BIFE-Cycler 설치/운영 매뉴얼\\n\\n어플리케이션의 설치를 위해서 필요한 인프라 소프트웨어/서버를 설치합니다. 다음과 같은 순서로 설치합니다.\\n\\n참고로 운영서버는 다음과 같습니다.\\n\\nSignet Production Servers\\n=======================\\n\\n```\\n| Server      | Inner IP    |  Port   | OS Version         |\\n|-------------|-------------|---------|--------------------|\\n| server-1    | 192.168.0.11|  43011  | Ubuntu 24.04.1 LTS |\\n| server-2    | 192.168.0.12|  43012  | Ubuntu 24.04.1 LTS |\\n| server-3    | 192.168.0.13|  43013  | Ubuntu 24.04.1 LTS |\\n| server-4    | 192.168.0.14|  43014  | Ubuntu 24.04.1 LTS |\\n```\\n\\n설치 순서는 크게 6개의 단계로 나누어 집니다.\\n\\n- 환경준비\\n- 도커 설치\\n- DB 설치\\n- 카프카설치\\n- 어플리케이션 설치\\n- 카프카 클라이언트(데이터 수집) 설치\\n\\n\\n각 서버는 /(root)에 /data directory 를 다음과 같이 가지고 있습니다.\\n```bash \\n/data\\n├── config # 설정화일\\n│   └── kafka\\n│       └── server.properties\\n├── db # postgresql data 저장소\\n│   └── pgdata\\n│       ├── conf\\n│       │   ├── pg_hba.conf\\n│       │   └── postgresql.conf\\n│       ├── data  [error opening dir]\\n│       └── lock\\n│           └── master.lock\\n└── kafka # kafka 데이터 저장소\\n    ├── data\\n    │   ├── data\\n    │   └── meta\\n    └── logs\\n```\\n\\n아래에 순서대로 설치 방법을 기술합니다.\\n\\n## 1. Docker 설치\\n\\n모든 서버에 도커를 설치해야 합니다. 본 어플리케이션은 Docker 기반으로 운영됩니다.\\n먼저, Ubuntu Server 20.04 LTS에서 도커를 설치하는 방법을 안내합니다.\\n\\n### Step 1: Update your system\\n\\n소프트웨어를 설치하기 전에 패키지 목록이 최신인지 확인하는 것이 좋습니다. 다음 명령어로 수행할 수 있습니다:\\n```\\nsudo apt-get update\\nsudo apt-get install ca-certificates curl\\n```\\n### Step 2: Install Docker Engine on Ubuntu Server\\n\\n도커를 아래와 같이 설치합니다.\\n\\n```bash\\ncd installation\\ncd 1.prerequisites\\n./install-docker.sh \\n```\\n\\ninstall-docker.sh 의 내용은 아래와 같습니다.\\n\\n```bash\\n# Add Docker\\'s official GPG key:\\nsudo install -m 0755 -d /etc/apt/keyrings \\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\\nsudo chmod a+r /etc/apt/keyrings/docker.asc\\n\\n# Add the repository to Apt sources:\\necho \\\\\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\\\\n  $(. /etc/os-release && echo \"$VERSION_CODENAME\") stable\" | \\\\\\n  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\\nsudo apt-get update\\n\\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\\nsudo docker run hello-world # optional\\nsudo usermod -aG docker $USER\\n\\n```\\n***\\n###\\n\\n\\n## 2. Database 설치 및 실행\\n\\n먼저 DB를 저장하기 위한 데이터 저장소를 준비합니다. (1번/2번 서버에 적용)\\n이는 Docker 기반의 DB가 restart 되더라도 data를 유지하기 위함입니다.\\n\\n### Data 저장소 구성\\n\\n```bash\\ncd /\\nmkdir data\\ncd data\\nmkdir db\\n```\\n\\n저장소가 만들어 지면 이를 이용하여 postgresql을 실행합니다. \\n서버 1/2 에 postgresql의 저장소가 만들어 지며, 서버 3은 DB의 이상유무를 탐지하기 위한 repmgr를 사용합니다. 이를 통해 서버 1 또는 2에서 이상유무가 발견되면 자동으로 Failover(Standby -> Primary) 전환이 일어납니다.\\n\\n각각의 서버에 DB를 설치하기 위한 명령어는 다음과 같습니다.\\n\\n```bash\\ncd ~/installation/2.postgresql\\n./run-as-active.sh \\n```\\n\\n#### ~/installation/2.postgresql/run-as-active.sh\\n```bash\\ndocker run -p 5432:5432 -d --name pg-0  \\\\\\n --log-driver=json-file --log-opt max-size=10m --log-opt max-file=5 \\\\\\n -v /data/db/pgdata:/bitnami/postgresql \\\\\\n --env TZ=Asia/Seoul \\\\\\n --env REPMGR_PARTNER_NODES=pg-0,pg-1 \\\\\\n --env REPMGR_NODE_NAME=pg-0 \\\\\\n --env REPMGR_NODE_NETWORK_NAME=192.168.0.11  \\\\\\n --env REPMGR_PRIMARY_HOST=192.168.0.11 \\\\\\n --env REPMGR_PASSWORD=repmgrpass   \\\\\\n --env POSTGRESQL_POSTGRES_PASSWORD=Skcc12345678! \\\\\\n --env POSTGRESQL_USERNAME=signet \\\\\\n --env POSTGRESQL_DATABASE=signet \\\\\\n --env POSTGRESQL_PASSWORD=Signet12345678! \\\\\\n bitnami/postgresql-repmgr:latest\\n```\\n\\n아래의 명령은 Server 1이 Down되었을 경우, Server 2가 Primary로 전환되는 데, 이후 Server 1을 복구하였을 때이를 Standby로 실행하기 위한 스크립트입니다. \\n\\n```bash\\ncd ~/installation/2.postgresql\\n./run-as-standby.sh\\n```\\n\\n`REPMGR_PRIMARY_HOST`를 `192.168.0.12`로 지정하여 DB를 실행합니다. \\n\\n아래는 `run-as-standby.sh`의 내용입니다.\\n\\n```bash\\n# ~/installation/2.postgresql/run-as-standby.sh\\ndocker run -p 5432:5432 -d --name pg-0  \\\\\\n --log-driver=json-file --log-opt max-size=10m --log-opt max-file=5 \\\\\\n -v /data/db/pgdata:/bitnami/postgresql \\\\\\n --env TZ=Asia/Seoul \\\\\\n --env REPMGR_PARTNER_NODES=pg-0,pg-1 \\\\\\n --env REPMGR_NODE_NAME=pg-0 \\\\\\n --env REPMGR_NODE_NETWORK_NAME=192.168.0.11  \\\\\\n --env REPMGR_PRIMARY_HOST=192.168.0.12 \\\\\\n --env REPMGR_PASSWORD=repmgrpass   \\\\\\n --env POSTGRESQL_POSTGRES_PASSWORD=Skcc12345678! \\\\\\n --env POSTGRESQL_USERNAME=signet \\\\\\n --env POSTGRESQL_DATABASE=signet \\\\\\n --env POSTGRESQL_PASSWORD=Signet12345678! \\\\\\n bitnami/postgresql-repmgr:latest\\n```\\n\\n정상적으로 실행되었을 경우 다음과 같은 화면을 확인할 수 있습니다. \\n\\n(아래 pg-1이 standby 로 접속되었다는 것은 server-2, server-3 에 각각 pg-1, pgp 를 실행하고 난 뒤 확인할 수 있습니다.)\\n\\n```bash\\nkcl@kcl-1:~$ docker logs -f -n 100 pg-0\\npostgresql-repmgr 13:26:44.93 INFO  ==>\\npostgresql-repmgr 13:26:44.93 INFO  ==> Welcome to the Bitnami postgresql-repmgr container\\npostgresql-repmgr 13:26:44.93 INFO  ==> Subscribe to project updates by watching https://github.com/bitnami/containers\\npostgresql-repmgr 13:26:44.93 INFO  ==> Submit issues and feature requests at https://github.com/bitnami/containers/issues\\npostgresql-repmgr 13:26:44.94 INFO  ==> Upgrade to Tanzu Application Catalog for production environments to access custom-configured and pre-packaged software components. Gain enhanced features, including Software Bill of Materials (SBOM), CVE scan result reports, and VEX documents. To learn more, visit https://bitnami.com/enterprise\\npostgresql-repmgr 13:26:44.94 INFO  ==>\\npostgresql-repmgr 13:26:44.95 INFO  ==> ** Starting PostgreSQL with Replication Manager setup **\\npostgresql-repmgr 13:26:44.96 INFO  ==> Validating settings in REPMGR_* env vars...\\npostgresql-repmgr 13:26:44.97 INFO  ==> Validating settings in POSTGRESQL_* env vars..\\npostgresql-repmgr 13:26:44.97 INFO  ==> Querying all partner nodes for common upstream node...\\npostgresql-repmgr 13:26:45.00 INFO  ==> This node was acting as a primary before restart!\\npostgresql-repmgr 13:26:45.00 INFO  ==> Can not find new primary. Starting PostgreSQL normally...\\npostgresql-repmgr 13:26:45.00 INFO  ==> There are no nodes with primary role. Assuming the primary role...\\npostgresql-repmgr 13:26:45.00 INFO  ==> Preparing PostgreSQL configuration...\\npostgresql-repmgr 13:26:45.01 INFO  ==> postgresql.conf file not detected. Generating it...\\npostgresql-repmgr 13:26:45.05 INFO  ==> Preparing repmgr configuration...\\npostgresql-repmgr 13:26:45.06 INFO  ==> Initializing Repmgr...\\npostgresql-repmgr 13:26:45.06 INFO  ==> Initializing PostgreSQL database...\\npostgresql-repmgr 13:26:45.07 INFO  ==> Custom configuration /opt/bitnami/postgresql/conf/postgresql.conf detected\\npostgresql-repmgr 13:26:45.07 INFO  ==> Custom configuration /opt/bitnami/postgresql/conf/pg_hba.conf detected\\npostgresql-repmgr 13:26:45.08 INFO  ==> Deploying PostgreSQL with persisted data...\\npostgresql-repmgr 13:26:45.10 INFO  ==> Configuring replication parameters\\npostgresql-repmgr 13:26:45.11 INFO  ==> Configuring fsync\\n\\npostgresql-repmgr 13:26:45.12 INFO  ==> ** PostgreSQL with Replication Manager setup finished! **\\npostgresql-repmgr 13:26:45.14 INFO  ==> Starting PostgreSQL in background...\\npg_ctl: another server might be running; trying to start server anyway\\nserver starting\\n2025-01-14 04:26:45.165 GMT [143] LOG:  pgaudit extension initialized\\n2025-01-14 04:26:45.171 GMT [143] LOG:  redirecting log output to logging collector process\\n2025-01-14 04:26:45.171 GMT [143] HINT:  Future log output will appear in directory \"/opt/bitnami/postgresql/logs\".\\n2025-01-14 04:26:45.171 GMT [143] LOG:  starting PostgreSQL 16.4 on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit\\n2025-01-14 04:26:45.172 GMT [143] LOG:  listening on IPv4 address \"0.0.0.0\", port 5432\\n2025-01-14 04:26:45.172 GMT [143] LOG:  listening on IPv6 address \"::\", port 5432\\n2025-01-14 04:26:45.174 GMT [143] LOG:  listening on Unix socket \"/tmp/.s.PGSQL.5432\"\\n2025-01-14 04:26:45.178 GMT [149] LOG:  database system was interrupted; last known up at 2025-01-13 05:30:40 GMT\\n2025-01-14 04:26:45.188 GMT [149] LOG:  database system was not properly shut down; automatic recovery in progress\\n2025-01-14 04:26:45.192 GMT [149] LOG:  invalid record length at 0/1E1D17B0: expected at least 24, got 0\\n2025-01-14 04:26:45.192 GMT [149] LOG:  redo is not required\\n2025-01-14 04:26:45.194 GMT [147] LOG:  checkpoint starting: end-of-recovery immediate wait\\n2025-01-14 04:26:45.199 GMT [147] LOG:  checkpoint complete: wrote 3 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.002 s, sync=0.001 s, total=0.006 s; sync files=2, longest=0.001 s, average=0.001 s; distance=0 kB, estimate=0 kB; lsn=0/1E1D17B0, redo lsn=0/1E1D17B0\\n2025-01-14 04:26:45.202 GMT [143] LOG:  database system is ready to accept connections\\npostgresql-repmgr 13:26:46.16 INFO  ==> ** Starting repmgrd **\\n[2025-01-14 13:26:46] [NOTICE] repmgrd (repmgrd 5.4.1) starting up\\nINFO:  set_repmgrd_pid(): provided pidfile is /tmp/repmgrd.pid\\n[2025-01-14 13:26:46] [NOTICE] starting monitoring of node \"pg-0\" (ID: 1000)\\n[2025-01-14 13:26:46] [NOTICE] monitoring cluster primary \"pg-0\" (ID: 1000)\\n2025-01-14 04:28:10.168 GMT [147] LOG:  checkpoint starting: immediate force wait\\n2025-01-14 04:28:10.243 GMT [147] LOG:  checkpoint complete: wrote 2 buffers (0.0%); 0 WAL file(s) added, 1 removed, 0 recycled; write=0.012 s, sync=0.022 s, total=0.076 s; sync files=2, longest=0.017 s, average=0.011 s; distance=14522 kB, estimate=14522 kB; lsn=0/1F000060, redo lsn=0/1F000028\\n[2025-01-14 13:28:16] [NOTICE] new standby \"pg-1\" (ID: 1001) has connected\\n```\\n\\n다음은 Server 2에 DB를 실행할 때는 Standby 모드로 실행합니다. 이는 REPMGR_PRIMARY_HOST를 서버 1(192.168.0.11)로 지정함으로 Standby 모드로 진입합니다.\\n\\n```bash\\nssh kcl@192.168.0.12 # kcl2 서버로 로그인\\ncd ~/installation/2.postgresql\\n./run-as-standby.sh\\n```\\n\\n아래는 `run-as-standby.sh`의 내용입니다.\\n\\n```bash\\n# ~/installation/2.postgresql/run-as-standby.sh\\ndocker run -p 5432:5432 -d --name pg-1  \\\\\\n --log-driver=json-file --log-opt max-size=10m --log-opt max-file=5 \\\\\\n -v /data/db/pgdata:/bitnami/postgresql \\\\\\n --env TZ=Asia/Seoul \\\\\\n --env REPMGR_PARTNER_NODES=pg-0,pg-1 \\\\\\n --env REPMGR_NODE_NAME=pg-1 \\\\\\n --env REPMGR_NODE_NETWORK_NAME=192.168.0.12  \\\\\\n --env REPMGR_PRIMARY_HOST=192.168.0.11 \\\\\\n --env REPMGR_PASSWORD=repmgrpass   \\\\\\n --env POSTGRESQL_POSTGRES_PASSWORD=Skcc12345678! \\\\\\n --env POSTGRESQL_USERNAME=signet \\\\\\n --env POSTGRESQL_DATABASE=signet \\\\\\n --env POSTGRESQL_PASSWORD=Signet12345678! \\\\\\n bitnami/postgresql-repmgr:latest\\n```\\n\\n만약 Server 2 를 Primary 로 실행하기 위해서는 `run-as-active.sh`을 실행합니다.\\n\\n```bash\\n# ~/installation/2.postgresql/run-as-active.sh\\ndocker run -p 5432:5432 -d --name pg-0  \\\\\\n --log-driver=json-file --log-opt max-size=10m --log-opt max-file=5 \\\\\\n -v /data/db/pgdata:/bitnami/postgresql \\\\\\n --env TZ=Asia/Seoul \\\\\\n --env REPMGR_PARTNER_NODES=pg-0,pg-1 \\\\\\n --env REPMGR_NODE_NAME=pg-1 \\\\\\n --env REPMGR_NODE_NETWORK_NAME=192.168.0.12  \\\\\\n --env REPMGR_PRIMARY_HOST=192.168.0.12 \\\\\\n --env REPMGR_PASSWORD=repmgrpass   \\\\\\n --env POSTGRESQL_POSTGRES_PASSWORD=Skcc12345678! \\\\\\n --env POSTGRESQL_USERNAME=signet \\\\\\n --env POSTGRESQL_DATABASE=signet \\\\\\n --env POSTGRESQL_PASSWORD=Signet12345678! \\\\\\n bitnami/postgresql-repmgr:latest\\n```\\n\\n이상과 같이 설치를 하고 난뒤 `docker ps`를 실행하여 보면 다음과 같이 실행되어 있는 것을 볼 수 있습니다.\\n\\n```bash\\n\\nkcl@kcl-2:~/installation/2.postgresql$ docker ps\\nCONTAINER ID   IMAGE                              COMMAND                  CREATED         STATUS         PORTS                                                           NAMES\\nbfa5af3e6431   bitnami/postgresql-repmgr:latest   \"/opt/bitnami/script…\"   2 seconds ago   Up 2 seconds   0.0.0.0:5432->5432/tcp, :::5432->5432/tcp                       pg-1 \\n\\nkcl@kcl-2:~/installation/2.postgresql$ docker logs -f -n 100 pg-1\\npostgresql-repmgr 13:00:15.83 INFO  ==>\\npostgresql-repmgr 13:00:15.83 INFO  ==> Welcome to the Bitnami postgresql-repmgr container\\npostgresql-repmgr 13:00:15.83 INFO  ==> Subscribe to project updates by watching https://github.com/bitnami/containers\\npostgresql-repmgr 13:00:15.83 INFO  ==> Submit issues and feature requests at https://github.com/bitnami/containers/issues\\npostgresql-repmgr 13:00:15.83 INFO  ==> Upgrade to Tanzu Application Catalog for production environments to access custom-configured and pre-packaged software components. Gain enhanced features, including Software Bill of Materials (SBOM), CVE scan result reports, and VEX documents. To learn more, visit https://bitnami.com/enterprise\\npostgresql-repmgr 13:00:15.84 INFO  ==>\\npostgresql-repmgr 13:00:15.85 INFO  ==> ** Starting PostgreSQL with Replication Manager setup **\\npostgresql-repmgr 13:00:15.87 INFO  ==> Validating settings in REPMGR_* env vars...\\npostgresql-repmgr 13:00:15.87 INFO  ==> Validating settings in POSTGRESQL_* env vars..\\npostgresql-repmgr 13:00:15.87 INFO  ==> Querying all partner nodes for common upstream node...\\npostgresql-repmgr 13:00:15.93 INFO  ==> Node configured as standby\\npostgresql-repmgr 13:00:15.93 INFO  ==> Preparing PostgreSQL configuration...\\npostgresql-repmgr 13:00:15.93 INFO  ==> postgresql.conf file not detected. Generating it...\\npostgresql-repmgr 13:00:15.98 INFO  ==> Preparing repmgr configuration...\\npostgresql-repmgr 13:00:15.99 INFO  ==> Initializing Repmgr...\\npostgresql-repmgr 13:00:15.99 INFO  ==> Waiting for primary node...\\n```\\n\\nDB 구성의 마지막으로 Server-3 에서 REPMGR 을 설치합니다. \\n\\n```bash\\ncd ~/installation/2.postgresql\\n./pgp.sh\\n```\\n\\n위의 프로그램은 Server-1, Server-2 에 있는 DB를 모니터링하고, 문제가 발생하였을 때 이를 자동으로  Failover 해 주는 용도입니다.\\n\\n또한, DB 커넥션을 현재 Active 인 DB로 맺어주는 역할을 합니다. 그러므로 Application 또는 DB Client 는 Server-1, Server-2 에 개별로 접속하지 않고 `192.168.0.13` 를 이용하여 접속합니다.\\n\\n상기 `pgp.sh`의 내용은 다음과 같습니다.\\n\\n```bash\\nkcl@kcl-dev:~/installation/2.postgresql$ cat pgp.sh\\ndocker run --restart always -p 6532:5432 --log-driver=json-file --log-opt max-size=10m --log-opt max-file=5  \\\\\\n        --network=host \\\\\\n        -d --name pgp1 \\\\\\n--env PGPOOL_AUTO_FAILBACK=yes   \\\\\\n--env PGPOOL_BACKEND_APPLICATION_NAMES=pg-0,pg-1  \\\\\\n--env PGPOOL_BACKEND_NODES=0:pg-0:5432,1:pg-1:5432 \\\\\\n--env PGPOOL_SR_CHECK_USER=postgres \\\\\\n--env PGPOOL_SR_CHECK_PASSWORD=Skcc12345678! \\\\\\n--env PGPOOL_NUM_INIT_CHILDREN=64 \\\\\\n--env PGPOOL_POSTGRES_USERNAME=signet    \\\\\\n--env PGPOOL_POSTGRES_PASSWORD=Signet12345678!    \\\\\\n--env PGPOOL_ADMIN_USERNAME=pgpadmin    \\\\\\n--env PGPOOL_ADMIN_PASSWORD=Skcc12345678! bitnami/pgpool:latest   \\n```\\n\\n정상 실행되었는지의 여부를 `docker logs -f pgp1`을 통해서 다음과 같이 확인할 수 있습니다.\\n\\n```bash\\nkcl@kcl-dev:~/installation/2.postgresql$ docker logs -f pgp1\\npgpool 04:43:47.29 INFO  ==>\\npgpool 04:43:47.29 INFO  ==> Welcome to the Bitnami pgpool container\\npgpool 04:43:47.29 INFO  ==> Subscribe to project updates by watching https://github.com/bitnami/containers\\npgpool 04:43:47.29 INFO  ==> Submit issues and feature requests at https://github.com/bitnami/containers/issues\\npgpool 04:43:47.29 INFO  ==> Upgrade to Tanzu Application Catalog for production environments to access custom-configured and pre-packaged software components. Gain enhanced features, including Software Bill of Materials (SBOM), CVE scan result reports, and VEX documents. To learn more, visit https://bitnami.com/enterprise\\npgpool 04:43:47.29 INFO  ==>\\npgpool 04:43:47.30 INFO  ==> ** Starting Pgpool-II setup **\\npgpool 04:43:47.32 INFO  ==> Validating settings in PGPOOL_* env vars...\\npgpool 04:43:47.33 INFO  ==> Initializing Pgpool-II...\\npgpool 04:43:47.33 INFO  ==> Generating pg_hba.conf file...\\npgpool 04:43:47.33 INFO  ==> Generating pgpool.conf file...\\npgpool 04:43:47.42 INFO  ==> Generating password file for local authentication...\\npgpool 04:43:47.42 INFO  ==> Generating password file for pgpool admin user...\\npgpool 04:43:47.43 INFO  ==> ** Pgpool-II setup finished! **\\n\\npgpool 04:43:47.44 INFO  ==> ** Starting Pgpool-II **\\n2025-01-14 04:43:47.454: main pid 1: LOG:  Backend status file /opt/bitnami/pgpool/logs/pgpool_status does not exist\\n2025-01-14 04:43:47.454: main pid 1: LOG:  health_check_stats_shared_memory_size: requested size: 12288\\n2025-01-14 04:43:47.454: main pid 1: LOG:  memory cache initialized\\n2025-01-14 04:43:47.454: main pid 1: DETAIL:  memcache blocks :64\\n2025-01-14 04:43:47.454: main pid 1: LOG:  allocating (144190784) bytes of shared memory segment\\n2025-01-14 04:43:47.455: main pid 1: LOG:  allocating shared memory segment of size: 144190784\\n2025-01-14 04:43:47.517: main pid 1: LOG:  health_check_stats_shared_memory_size: requested size: 12288\\n2025-01-14 04:43:47.517: main pid 1: LOG:  health_check_stats_shared_memory_size: requested size: 12288\\n2025-01-14 04:43:47.517: main pid 1: LOG:  memory cache initialized\\n2025-01-14 04:43:47.517: main pid 1: DETAIL:  memcache blocks :64\\n2025-01-14 04:43:47.518: main pid 1: LOG:  pool_discard_oid_maps: discarded memqcache oid maps\\n2025-01-14 04:43:47.529: main pid 1: LOG:  create socket files[0]: /opt/bitnami/pgpool/tmp/.s.PGSQL.5432\\n2025-01-14 04:43:47.529: main pid 1: LOG:  listen address[0]: *\\n2025-01-14 04:43:47.529: main pid 1: LOG:  Setting up socket for 0.0.0.0:5432\\n2025-01-14 04:43:47.529: main pid 1: LOG:  Setting up socket for :::5432\\n2025-01-14 04:43:47.534: main pid 1: LOG:  find_primary_node_repeatedly: waiting for finding a primary node\\n2025-01-14 04:43:47.573: main pid 1: LOG:  find_primary_node: primary node is 0\\n2025-01-14 04:43:47.573: main pid 1: LOG:  find_primary_node: standby node is 1\\n2025-01-14 04:43:47.573: main pid 1: LOG:  create socket files[0]: /opt/bitnami/pgpool/tmp/.s.PGSQL.9898\\n2025-01-14 04:43:47.573: main pid 1: LOG:  listen address[0]: localhost\\n2025-01-14 04:43:47.574: main pid 1: LOG:  Setting up socket for ::1:9898\\n2025-01-14 04:43:47.574: main pid 1: LOG:  Setting up socket for 127.0.0.1:9898\\n2025-01-14 04:43:47.574: pcp_main pid 174: LOG:  PCP process: 174 started\\n2025-01-14 04:43:47.574: sr_check_worker pid 175: LOG:  process started\\n2025-01-14 04:43:47.574: health_check pid 176: LOG:  process started\\n2025-01-14 04:43:47.574: health_check pid 177: LOG:  process started\\n2025-01-14 04:43:47.575: main pid 1: LOG:  pgpool-II successfully started. version 4.5.4 (hotooriboshi)\\n2025-01-14 04:43:47.575: main pid 1: LOG:  node status[0]: 1\\n2025-01-14 04:43:47.575: main pid 1: LOG:  node status[1]: 2\\n\\n```\\n## 3. Kafka 설치\\n\\nkafka 설정을 저장하기 위하여 다음의 경로를 작성합니다. 카프카의 설정은 1/2/3 번 서버 모두 `/data/config/kafka/server.properties`에 저장됩니다.\\n\\n```bash\\n# /data/config/kafka\\ncd /data\\nmkdir config\\ncd config\\nmkdir kafka\\ncd kafka\\n\\n```\\n\\n그리고 `vi server.properties` 를 실행하여 아래의 내용을 저장합니다.\\n`/data/config/kafka/server.properties` 의 내용은 다음과 같습니다. \\n\\n(2, 3번은 node.id 와 advertised.listener 를 변경하여 적용합니다.)\\n\\n```bash\\n# Broker ID - must be unique across all brokers\\nnode.id=1 # 2, 3 for 192.168.0.12, 192.168.0.13\\n\\n# The directory where Kafka will store logs, including metadata logs\\nlog.dirs=/var/lib/kafka/data\\n\\n# Enable KRaft mode by setting the process.roles property\\n# Setting the role to \\'broker,controller\\' means this node acts as both a broker and a controller\\nprocess.roles=broker,controller\\n\\n# The address the broker should bind to\\nlistener.security.protocol.map=PLAINTEXT_LOCAL:PLAINTEXT,PLAINTEXT_TUNNEL:PLAINTEXT,CONTROLLER:PLAINTEXT\\nlisteners=PLAINTEXT_TUNNEL://0.0.0.0:9094,PLAINTEXT_LOCAL://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093\\n#advertised.listeners=PLAINTEXT://kcl1.signet:9092\\nadvertised.listeners=PLAINTEXT_TUNNEL://localhost:9094,PLAINTEXT_LOCAL://192.168.0.11:9092 # node2 => 192.168.0.12, node3 => 192.168.0.13 으로 변경\\n# The address the controller should bind to (use different ports if necessary)\\ncontroller.listener.names=CONTROLLER\\n# listener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT\\ninter.broker.listener.name=PLAINTEXT_LOCAL\\n\\n# Quorum Voters - list of all brokers eligible to participate in the quorum (node.id@address)\\n# Include all brokers that are part of the KRaft quorum\\ncontroller.quorum.voters=1@192.168.0.11:9093,2@192.168.0.12:9093,3@192.168.0.13:9093\\n\\n# Log settings\\nlog.retention.hours=168\\nlog.segment.bytes=1073741824\\n\\n# Other configurations (adjust as necessary)\\nnum.network.threads=3\\nnum.io.threads=8\\nsocket.send.buffer.bytes=102400\\nsocket.receive.buffer.bytes=102400\\nsocket.request.max.bytes=104857600\\n\\nmax.message.bytes=104857600  # 100 MB\\n# producer config => max.request.size=104857600\\n# consumer config => max.partition.fetch.bytes=104857600\\n\\n# Zookeeper settings are not required in KRaft mode, ensure any Zookeeper-related configs are removed or commented out\\n# zookeeper.connect=localhost:2181\\n\\n# Metadata storage directory\\nmetadata.log.dir=/var/lib/kafka/meta\\n\\n# Specify the initial broker quorum replication factor\\n# Generally, this should be at least 3 for production setups\\noffsets.topic.replication.factor=3\\ntransaction.state.log.replication.factor=3\\ntransaction.state.log.min.isr=2\\n\\n\\n# Miscellaneous settings\\nauto.create.topics.enable=false\\ndelete.topic.enable=true\\ndefault.replication.factor=3\\n```\\n\\n위와 같이 kafka 구성을 저장한뒤 다음의 명령어를 통하여 kafka를 실행합니다. (1,2,3 번 서버각각 실행)\\n```bash\\ncd ~/installation/2.kafka/run-kafka.sh\\n```\\n\\n참고로 위의 스크립트의 내용은 아래와 같습니다.\\n\\n```bash\\ndocker run --name kafka-1 -d --restart always \\\\\\n-p 9092:9092 -p 9093:9093 -p 9094:9094 \\\\\\n-v /data/config/kafka:/mnt/shared/config \\\\\\n-v /data/kafka/data:/var/lib/kafka \\\\\\n-v /data/kafka/logs:/var/log/kafka \\\\\\n--log-driver=json-file --log-opt max-size=10m --log-opt max-file=20 \\\\\\napache/kafka:latest\\n```\\n\\n정상적으로 실행되었을 경우 `docker ps`를 실행하였을 때 다음과 같은 메세지를 확인할 수 있습니다.\\n\\n```bash\\n# 카프카 instance 생성 여부 확인\\nkcl@kcl-2:~/installation/3.kafka$ docker ps\\nCONTAINER ID   IMAGE                 COMMAND                  CREATED      STATUS      PORTS                                                           NAMES\\nfe3bcafcfbcf   apache/kafka:latest   \"/__cacert_entrypoin…\"   7 days ago   Up 3 days   0.0.0.0:9092-9094->9092-9094/tcp, :::9092-9094->9092-9094/tcp   kafka-2\\n\\n# 카프카 정상실행 여부 확인\\nkcl@kcl-2:~/installation/3.kafka$ docker logs -f kafka-2 | more\\n===> User\\nuid=1000(appuser) gid=1000(appuser) groups=1000(appuser)\\n===> Setting default values of environment variables if not already set.\\nCLUSTER_ID not set. Setting it to default value: \"5L6g3nShT-eMCtK--X86sw\"\\n===> Configuring ...\\n===> Launching ...\\n===> Using provided cluster id 5L6g3nShT-eMCtK--X86sw ...\\n[2025-01-07 04:36:54,020] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)\\n[2025-01-07 04:36:54,056] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util) [2025-01-07 04:36:54,057] INFO RemoteLogManagerConfig values:\\n        log.local.retention.bytes = -2\\n        log.local.retention.ms = -2\\n        remote.fetch.max.wait.ms = 500\\n        remote.log.index.file.cache.total.size.bytes = 1073741824\\n        remote.log.manager.copier.thread.pool.size = 10\\n        remote.log.manager.copy.max.bytes.per.second = 9223372036854775807\\n        remote.log.manager.copy.quota.window.num = 11\\n        remote.log.manager.copy.quota.window.size.seconds = 1\\n        remote.log.manager.expiration.thread.pool.size = 10\\n        remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807\\n        remote.log.manager.fetch.quota.window.num = 11\\n        remote.log.manager.fetch.quota.window.size.seconds = 1\\n        remote.log.manager.task.interval.ms = 30000\\n        remote.log.manager.task.retry.backoff.max.ms = 30000\\n        remote.log.manager.task.retry.backoff.ms = 500\\n        remote.log.manager.task.retry.jitter = 0.2\\n        remote.log.manager.thread.pool.size = 10\\n        remote.log.metadata.custom.metadata.max.bytes = 128\\n        remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager\\n        remote.log.metadata.manager.class.path = null\\n        remote.log.metadata.manager.impl.prefix = rlmm.config.\\n        remote.log.metadata.manager.listener.name = null\\n        remote.log.reader.max.pending.tasks = 100\\n        remote.log.reader.threads = 10\\n        remote.log.storage.manager.class.name = null\\n        remote.log.storage.manager.class.path = null\\n        remote.log.storage.manager.impl.prefix = rsm.config.\\n        remote.log.storage.system.enable = false\\n```\\n\\n\\n만약 SSL 통신을 위하여는 java의 keytool을 이용하여 다음과 같이 SSL 인증서를 생성하여 설정합니다.\\n\\n```bash\\nsudo apt install openjdk-17-jre-headless                                                                     \\nmkdir keys                                                                                                   \\ncd keys/                                                                                                     \\nkeytool -genkeypair -alias ca -keyalg RSA -keysize 2048 -storetype PKCS12 \\\\\\n   -keystore ca.p12 -validity 365 -dname \"CN=KafkaCA, OU=None, O=None, L=None, S=None, C=None\"   -ext bc:c\\n \\nkeytool -export -alias ca -file ca.crt -keystore ca.p12\\nkeytool -genkeypair -alias kafka-server -keyalg RSA -keysize 2048 \\\\\\n  -storetype PKCS12 -keystore server.p12 -validity 365   -dname \"CN=kafka-broker, OU=None, O=None, L=None, S=None, C=None\"\\nkeytool -certreq -alias kafka-server -file server.csr -keystore server.p12\\nkeytool -gencert -validity 365 -alias ca -infile server.csr   -outfile server.crt -keystore ca.p12\\nkeytool -import -trustcacerts -alias ca -file ca.crt   -keystore server.p12\\nkeytool -import -alias kafka-server -file server.crt   -keystore server.p12\\nkeytool -import -alias ca -file ca.crt   -keystore client.truststore.p12\\nkeytool -genkeypair -alias kafka-client -keyalg RSA -keysize 2048 \\\\\\n  -storetype PKCS12 -keystore client.p12 -validity 365   -dname \"CN=kafka-client, OU=None, O=None, L=None, S=None, C=None\"\\n```\\n\\n\\n## 4. HAProxy 설치\\n\\n아래 HAProxy를 이용한 로드밸런싱 설정을 기술하였습니다. \\n\\n**중요) HAProxy 는 192.168.0.13 서버에 설정합니다.**\\n\\n```bash\\nsudo apt-get install haproxy\\ncd /etc/aproxy/                                                                                                  \\nsudo vi haproxy.cfg                                                                                               \\n```\\n\\nhaproxy.cfg 파일은 아래와 같이 설정합니다.\\n\\n\\n### /etc/haproxy.cfg\\n```bash\\nglobal\\n        log /dev/log    local0\\n        log /dev/log    local1 notice\\n        chroot /var/lib/haproxy\\n        stats socket /run/haproxy/admin.sock mode 660 level admin\\n        stats timeout 30s\\n        user haproxy\\n        group haproxy\\n        daemon\\n\\n        # Default SSL material locations\\n        ca-base /etc/ssl/certs\\n        crt-base /etc/ssl/private\\n\\n        # See: https://ssl-config.mozilla.org/#server=haproxy&server-version=2.0.3&config=intermediate\\n        ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\\n        ssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256\\n        ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets\\n\\ndefaults\\n        log     global\\n        mode    http\\n        option  httplog\\n        option  dontlognull\\n        timeout connect 5000\\n        timeout client  50000\\n        timeout server  50000\\n        errorfile 400 /etc/haproxy/errors/400.http\\n        errorfile 403 /etc/haproxy/errors/403.http\\n        errorfile 408 /etc/haproxy/errors/408.http\\n        errorfile 500 /etc/haproxy/errors/500.http\\n        errorfile 502 /etc/haproxy/errors/502.http\\n        errorfile 503 /etc/haproxy/errors/503.http\\n        errorfile 504 /etc/haproxy/errors/504.http\\n\\nfrontend signet_frontend\\n    bind *:80\\n    acl api_system_path path_beg -i /system/api\\n    acl api_signet_path path_beg -i /signet/api\\n\\n    use_backend api_system_server if api_system_path\\n    use_backend api_signet_server if api_signet_path\\n\\n    default_backend signet_client\\n\\nbackend signet_client\\n    server client1 192.168.0.11:8000\\n    server client2 192.168.0.12:8000\\n\\nbackend api_system_server\\n    http-request set-path \"%[path,regsub(^/system/api/,/api/)]\"\\n    server system_instance1 192.168.0.11:8003 # check\\n    server system_instance2 192.168.0.12:8003 # check\\n\\nbackend api_signet_server\\n    http-request set-path \"%[path,regsub(^/signet/api/,/api/)]\"\\n    server signet_instance1 192.168.0.11:8002 # check\\n    server signet_instance2 192.168.0.12:8002 # check\\n\\n```\\n\\n파일을 저장한 후 다음의 명령들을 실행하여 정상적으로 동작하는지의 여부를 확인합니다.\\n\\n```bash\\nkcl@kcl-dev:/etc/haproxy$ sudo systemctl restart haproxy.service\\nkcl@kcl-dev:/etc/haproxy$ sudo systemctl status haproxy.service\\n● haproxy.service - HAProxy Load Balancer\\n     Loaded: loaded (/usr/lib/systemd/system/haproxy.service; enabled; preset: enabled)\\n     Active: active (running) since Tue 2025-01-14 04:19:42 UTC; 7s ago\\n       Docs: man:haproxy(1)\\n             file:/usr/share/doc/haproxy/configuration.txt.gz\\n   Main PID: 14682 (haproxy)\\n     Status: \"Ready.\"\\n      Tasks: 17 (limit: 38049)\\n     Memory: 43.6M (peak: 46.0M)\\n        CPU: 87ms\\n     CGroup: /system.slice/haproxy.service\\n             ├─14682 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock\\n             └─14686 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock\\n\\nJan 14 04:19:42 kcl-dev systemd[1]: Starting haproxy.service - HAProxy Load Balancer...\\nJan 14 04:19:42 kcl-dev haproxy[14682]: [NOTICE]   (14682) : New worker (14686) forked\\nJan 14 04:19:42 kcl-dev haproxy[14682]: [NOTICE]   (14682) : Loading success.\\nJan 14 04:19:42 kcl-dev systemd[1]: Started haproxy.service - HAProxy Load Balancer.\\nkcl@kcl-dev:/etc/haproxy$\\n```\\n\\n\\n## 4. Application 설치\\n\\nServer 1, Server 2 각각 메인 어플리케이션을 실행해 줍니다. \\n```bash\\ncd ~/installation/4.application\\n./run-server.sh\\n```\\n\\nrun-server.sh 의 내용은 다음과 같습니다.\\n\\n\\n```bash\\naws ecr get-login-password --region ap-northeast-2 | docker login --username AWS --password-stdin 511662517913.dkr.ecr.ap-northeast-2.amazonaws.com\\n\\ndocker stop signet-server\\ndocker stop signet-system\\ndocker rm signet-server\\ndocker rm signet-system\\n\\n# Signet Server\\nlatest_tag=$(aws ecr describe-images --repository-name signet/signet-server | \\\\\\n        jq -r \\'.imageDetails | sort_by(.imagePushedAt) | last(.[]).imageTags[0]\\')\\necho \"Latest signet-server version : $latest_tag\"\\ndocker run -it -d -p 8002:8080 --name signet-server \\\\\\n        -e DB_URL=jdbc:postgresql://192.168.0.13:5432/signet \\\\\\n        -e DB_USERNAME=signet \\\\\\n        -e DB_PASSWORD=Signet12345678! \\\\\\n        511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-server:$latest_tag\\n# Signet Base System\\nlatest_tag=$(aws ecr describe-images --repository-name signet/signet-system | \\\\\\n        jq -r \\'.imageDetails | sort_by(.imagePushedAt) | last(.[]).imageTags[0]\\')\\necho \"Latest signet-server version : $latest_tag\"\\ndocker run -it -d -p 8003:8080 --name signet-system \\\\\\n        -e DB_URL=jdbc:postgresql://192.168.0.13:5432/signet \\\\\\n        -e DB_USERNAME=signet \\\\\\n        -e DB_PASSWORD=Signet12345678! \\\\\\n        -e TOKEN_TIMEOUT=43200 \\\\\\n        511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-system:$latest_tag\\n\\n# Client\\nlatest_tag=$(aws ecr describe-images --repository-name signet/signet-client | \\\\\\n        jq -r \\'.imageDetails | sort_by(.imagePushedAt) | last(.[]).imageTags[0]\\')\\necho \"Latest version : $latest_tag\"\\ndocker stop signet-client1\\ndocker rm signet-client1\\ndocker run -it -d -p 8000:80 --name signet-client1 511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-client:$latest_tag\\n\\n```\\n\\n이후 `docker ps`를 통해 어플리케이션의 instance가 잘 실행되었는지 확인합니다.\\n\\n```bash\\n# Server-1 에서 다음과 같은 instance들을 확인 할 수 있습니다.\\nkcl@kcl-1:~/installation/4.application$ docker ps\\nCONTAINER ID   IMAGE                                                                         COMMAND                  CREATED          STATUS          PORTS\\n                                        NAMES\\n42e74449e860   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-client:v-8    \"/docker-entrypoint.…\"   2 minutes ago    Up 2 minutes    0.0.0.0:8000->80/tcp, [::]:8000->80/tcp                         signet-client1\\n75efdd12f2e9   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-system:v-8    \"java -jar app.jar\"      2 minutes ago    Up 2 minutes    0.0.0.0:8003->8080/tcp, [::]:8003->8080/tcp                     signet-system\\nb0bd44830771   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-server:v-95   \"java -jar app.jar\"      2 minutes ago    Up 2 minutes    0.0.0.0:8002->8080/tcp, [::]:8002->8080/tcp                     signet-server\\n402f84836f18   bitnami/postgresql-repmgr:latest                                              \"/opt/bitnami/script…\"   22 minutes ago   Up 22 minutes   0.0.0.0:5432->5432/tcp, :::5432->5432/tcp                       pg-0\\nda70b14a280b   apache/kafka:latest                                                           \"/__cacert_entrypoin…\"   7 days ago       Up 3 days       0.0.0.0:9092-9094->9092-9094/tcp, :::9092-9094->9092-9094/tcp   kafka-1\\n\\n# 로그를 확인하여 제대로 실행되었는지 확인합니다. 일반적으로 최초 실행시 제일 뒷 라인의\\n# Started SignetApplication in 11.441 seconds (process running for 11.853) 를 확인합니다.\\n\\nkcl@kcl-1:~/installation/4.application$ docker logs -f signet-server\\n\\n  .   ____          _            __ _ _\\n /\\\\\\\\ / ___\\'_ __ _ _(_)_ __  __ _ \\\\ \\\\ \\\\ \\\\\\n( ( )\\\\___ | \\'_ | \\'_| | \\'_ \\\\/ _` | \\\\ \\\\ \\\\ \\\\\\n \\\\\\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\\n  \\'  |____| .__|_| |_|_| |_\\\\__, | / / / /\\n =========|_|==============|___/=/_/_/_/\\n :: Spring Boot ::                (v3.2.4)\\n\\n.\\n. # 생략\\n.\\n\\n2025-01-14T04:47:17.615Z  INFO 1 --- [Signet Service] [           main] o.s.s.web.DefaultSecurityFilterChain     : Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@bb832f0, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@1cdb691a, org.springframework.security.web.context.SecurityContextHolderFilter@4cd6143c, org.springframework.security.web.header.HeaderWriterFilter@4b5e664f, org.springframework.web.filter.CorsFilter@14656be5, org.springframework.security.web.authentication.logout.LogoutFilter@4d356547, com.skcc.bife.common.security.filter.JwtAuthenticationFilter@66ab924, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@2ae63c84, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@4c6f451b, org.springframework.security.web.session.SessionManagementFilter@1ecd979e, org.springframework.security.web.access.ExceptionTranslationFilter@a6bd353, org.springframework.security.web.access.intercept.AuthorizationFilter@60c7726b]\\n2025-01-14T04:47:17.926Z  INFO 1 --- [Signet Service] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port 8080 (http) with context path \\'\\'\\n2025-01-14T04:47:17.938Z  INFO 1 --- [Signet Service] [           main] com.skcc.bife.SignetApplication          : Started SignetApplication in 11.441 seconds (process running for 11.853)\\n```\\n\\n## 5. Kafka Client 설치 및 실행\\n\\n마지막으로 Kafka Client를 실행하여 데이터 수집 준비를 합니다.\\n먼저 topic을 만들어 두기 위하여 make-topics.sh 을 실행합니다. 이를 통해 `signet-msg-topic` 을 생성합니다.\\n```bash\\ncd ~/installation/5.subscriber\\n./make-topics.sh\\n\\n# list-topics.sh 을 통해 다음의 토픽이 생성되어 있는지 확인합니다.\\nkcl@kcl-1:~/installation/5.subscriber$ ./list-topics.sh\\n__consumer_offsets\\nsignet-bin-topic\\nsignet-msg-topic\\n\\n```\\n\\n./kafka-client.sh 을 실행하여 데이터 수집 준비를 합니다.\\n```bash\\n./kafka-client.sh\\n\\n# 실행후 docker ps를 통해 \"kafka-subscriber\"가 실행되어 있는 것을 확인할 수 있습니다.\\n\\nkcl@kcl-1:~/installation/5.subscriber$ docker ps\\nCONTAINER ID   IMAGE                                                                                  COMMAND                  CREATED          STATUS          PORTS\\n                                                 NAMES\\n8368c4b45ca0   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-kafka-subscriber:v-5   \"java -jar app.jar\"      15 seconds ago   Up 14 seconds\\n                                                 kafka-subscriber\\n\\nkcl@kcl-1:~/installation/5.subscriber$ docker logs kafka-subscriber\\nKAFKA_TOPIC_NAME: signet-msg-topic\\nKAFKA_BIN_TOPIC_NAME: signet-bin-topic\\nDATABASE_URL: jdbc:postgresql://192.168.0.13:5432/signet\\nDATABASE_USER: signet\\nBOOTSTRAP_SERVERS: 192.168.0.11:9092,192.168.0.12:9092,192.168.0.13:9092\\nRECONNECT_DELAY_MS: 5000\\nSLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\\nSLF4J: Defaulting to no-operation (NOP) logger implementation\\nSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\\nListening to : [signet-msg-topic, signet-bin-topic]\\n\\n2025-01-14T05:17:28 : Connected to the database.                                                 \\n```\\n\\n참고로, `kafka-client.sh`의 내용은 다음과 같습니다.\\n\\n```bash\\naws ecr get-login-password --region ap-northeast-2 | docker login --username AWS --password-stdin 511662517913.dkr.ecr.ap-northeast-2.amazonaws.com\\n\\ndocker stop signet-kafka-subscriber\\ndocker rm signet-kafka-subscriber\\n\\nlatest_tag=$(aws ecr describe-images --repository-name signet/signet-kafka-subscriber | \\\\\\n        jq -r \\'.imageDetails | sort_by(.imagePushedAt) | last(.[]).imageTags[0]\\')\\necho \"Latest version : $latest_tag\"\\ndocker run -it -d --name signet-kafka-subscriber \\\\\\n    -e DATABASE_URL jdbc:postgresql://rds-bife-dev.cluster-ctw6ta8xocaf.ap-northeast-2.rds.amazonaws.com:5432/signet-dev \\\\\\n    -e DATABASE_USER signet \\\\\\n    -e DATABASE_PASSWORD Bife6400! \\\\\\n    -e KAFKA_TOPIC signet-msg-topic \\\\\\n    511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-kafka-subscriber:$latest_tag\\n\\n```\\n\\n## 6. HTTPS\\n\\nlet\\'s encrypt 와 certbot을 활용하여 https 통신시 \\n\\n```bash\\nsudo apt-get install certbot\\nsudo certbot certonly\\ncd /etc/letsencrypt/\\n```\\n\\n```bash\\nfrontend https\\n    bind *:443 ssl crt /etc/<your cert>/fullchain.pem.key\\n    mode http\\n    option forwardfor\\n    option httpchk GET /healthcheck\\n\\n    # Set default backend\\n    default_backend your-backend-name\\n```\\n\\n## 7. 운영시 참고 사항\\n\\n### 정상적인 동작 확인 방법\\n\\n\\n### 1. DB\\n\\n- DB의 서버중 한대에 이상이 발생하였을 시, 다음과 같은 조치를 취합니다.\\n\\n1. Primary 서버에 이상이 발생하였을 경우,\\n- 기존의 Standby 서버가 Primary 서버로 전환되므로, 이전의 Primary 서버를 다시 실행할 때 이를 Standby 모드로 실행합니다.\\n\\n2. Standby 서버에 이상이 발생하였을 경우,\\n- Standby 서버에 이상이 발생하였을 경우, Primary Server의 전환이 일어나지 않으로, 기존대로 Standby 서버로 실행합니다.\\n\\n### 2. Kafka\\n- 카프카의 문제가 발생시 새로이 실행함으로, 카프카의 노드를 KRaft 클러스터에 다시 참여 시킵니다.\\n\\n### 3. Application\\n\\n- 어플리케이션은 위에서 제공된 스크립트를 통해 최신버전을 항상 최신 버전을 실행할 수 있습니다.\\n- 어플리케이션의 재배포시 위의 스크립트를 실행함으로 최신버전을 실행할 수 있습니다. \\n\\n\\n\\n\\n## A. 어플리케이션 실행 (요약)\\n\\n1. DB (pg-0, pg-1, pgp)\\n\\n./installation/2.postgresql/run-as-active.sh (Server 1에서 Active 상태로 실행) \\n./installation/2.postgresql/run-as-standby.sh (Server 2에서 Standby 상태로 실행)\\n./installation/2.postgresql/pgp.sh\\n\\n2. Kafka\\n\\n2. Application (signet-system, signet-server, signet-client1)\\n\\ncd ~/installation/4.application \\n./run-server.sh \\n\\n3. Kafka Client (docker kafka-subscriber)\\n\\ncd ~/installation/5.subscriber\\n./kafka-client.sh \\n\\n\\n## B. 문제해결\\n\\n- 서버별 정상 작동 여부 확인\\n\\nServer-1 에서 docker ps를 실행하였을때 다음의 6개 docker container list가 보여야 정상 작동 됩니다.\\n\\nsignet-client1, signet-system, signet-server, pg-0, kafka-1, kafka-subscriber\\n\\n```bash\\nkcl@kcl-1$ docker ps\\nCONTAINER ID   IMAGE                                                                                  COMMAND\\n          CREATED          STATUS          PORTS                                                           NAMES\\n19fdffc0872f   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-kafka-subscriber:v-5   \"java -jar app.jar\"      16 seconds ago   Up 16 seconds                                                                   kafka-subscriber\\n40d9f3a2bfe3   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-client:v-8             \"/docker-entrypoint.…\"   2 hours ago      Up 2 hours      0.0.0.0:8000->80/tcp, [::]:8000->80/tcp                         signet-client1\\nd5905121ad38   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-system:v-10            \"java -jar app.jar\"      2 hours ago      Up 2 hours      0.0.0.0:8003->8080/tcp, [::]:8003->8080/tcp                     signet-system\\n012fb23819dc   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-server:v-99            \"java -jar app.jar\"      2 hours ago      Up 2 hours      0.0.0.0:8002->8080/tcp, [::]:8002->8080/tcp                     signet-server\\n181a6488b318   bitnami/postgresql-repmgr:latest                                                       \"/opt/bitnami/script…\"   3 hours ago      Up 3 hours                                                                      pg-0\\nda70b14a280b   apache/kafka:latest                                                                    \"/__cacert_entrypoin…\"   7 days ago       Up 4 days       0.0.0.0:9092-9094->9092-9094/tcp, :::9092-9094->9092-9094/tcp   kafka-1\\n\\n```\\n\\nServer-2\\n\\npg-1, kafka-2, signet-server, signet-system, signet-client, kafka-subscriber\\n\\n```bash\\nkcl@kcl-2:~/installation/5.subscriber$ docker ps\\nCONTAINER ID   IMAGE                                                                                  COMMAND\\n          CREATED          STATUS          PORTS                                                           NAMES\\n2926664eb4a1   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-kafka-subscriber:v-5   \"java -jar app.jar\"      11 seconds ago   Up 10 seconds                                                                   kafka-subscriber\\nb0328b7644a8   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-client:v-8             \"/docker-entrypoint.…\"   2 hours ago      Up 2 hours      0.0.0.0:8000->80/tcp, [::]:8000->80/tcp                         signet-client1\\ne37bd4bdecbc   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-server:v-99            \"java -jar app.jar\"      2 hours ago      Up 2 hours      0.0.0.0:8002->8080/tcp, [::]:8002->8080/tcp                     signet-server\\n04bba3a327f7   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-system:v-10            \"java -jar app.jar\"      2 hours ago      Up 2 hours      0.0.0.0:8003->8080/tcp, [::]:8003->8080/tcp                     signet-system\\nc1b563a0c350   bitnami/postgresql-repmgr:latest                                                       \"/opt/bitnami/script…\"   18 hours ago     Up 3 hours                                                                      pg-1\\nfe3bcafcfbcf   apache/kafka:latest                                                                    \"/__cacert_entrypoin…\"   7 days ago       Up 4 days       0.0.0.0:9092-9094->9092-9094/tcp, :::9092-9094->9092-9094/tcp   kafka-2\\nkcl@kcl-2:~/installation/5.subscriber$\\n```\\n\\nServer-3 \\n\\n다음 2개의 instance(pgp1, kafka-3)와 haproxy가 정상작동하여야 합니다.\\n\\n```bash\\ncl@kcl-dev:~$ docker ps\\nCONTAINER ID   IMAGE                   COMMAND                  CREATED       STATUS       PORTS\\n                                      NAMES\\ndea7dbec4a00   bitnami/pgpool:latest   \"/opt/bitnami/script…\"   2 hours ago   Up 2 hours\\n                                      pgp1\\n61fc10a48541   apache/kafka:latest     \"/__cacert_entrypoin…\"   7 days ago    Up 4 days    0.0.0.0:9092-9094->9092-9094/tcp, :::9092-9094->9092-9094/tcp   kafka-3\\n\\nkcl@kcl-dev:~$ sudo systemctl status haproxy.service\\n● haproxy.service - HAProxy Load Balancer\\n     Loaded: loaded (/usr/lib/systemd/system/haproxy.service; enabled; preset: enabled)\\n     Active: active (running) since Wed 2025-01-15 03:59:39 UTC; 2s ago\\n       Docs: man:haproxy(1)\\n             file:/usr/share/doc/haproxy/configuration.txt.gz\\n   Main PID: 29417 (haproxy)\\n     Status: \"Ready.\"\\n      Tasks: 17 (limit: 38049)\\n     Memory: 43.7M (peak: 45.6M)\\n        CPU: 89ms\\n     CGroup: /system.slice/haproxy.service\\n             ├─29417 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.so>\\n             └─29419 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.so>\\n\\nJan 15 03:59:39 kcl-dev systemd[1]: Starting haproxy.service - HAProxy Load Balancer...\\nJan 15 03:59:39 kcl-dev haproxy[29417]: [NOTICE]   (29417) : New worker (29419) forked\\nJan 15 03:59:39 kcl-dev haproxy[29417]: [NOTICE]   (29417) : Loading success.\\nJan 15 03:59:39 kcl-dev systemd[1]: Started haproxy.service - HAProxy Load Balancer.\\n```\\n\\n\\n1. docker container 가 이미 사용중인 경우\\n\\n```bash\\ndocker: Error response from daemon: Conflict. The container name \"/pg-1\" is already in use by container \"50e98d1b0d083354704640babc6686b848cfc327560fb0106156e6c90def1cbf\". You have to remove (or rename) that container to be able to reuse that name.\\n```\\ndocker를 실행하다 다음과 같은 메시지가 나오면, 해당 이름이 사용중이므로 container(위의 경우에는 `pg-1`)을 제거하고 다시 실행합니다.\\n제거하는 방법은\\n\\n```bash\\ndocker rm pg-1\\n```\\n\\n입니다.\\n\\n\\n- Web Browser 접속이 되지 않는 경우\\n\\n```bash\\ndocker logs -f -n 1000 [instance name] \\n```\\n\\n을 실행하여 로그를 확인합니다. 로그의 해석이 불가능할 경우, 이를 캡춰해 개발사에 전달해 주세요.\\n(server1, server2의 signet-server,signet-system 에 대하여 로그를 각각 캡춰필요)\\n\\n- Data 가 들어오지 않는 경우\\n\\n먼저 server1 의 kafka-subscriber의 로그에서 데이타가 정상적으로 들어오는지 확인합니다. \\n```bash\\ndocker logs -f -n 1000 kafka-subscriber\\nCommand CHAMINFO received.\\nChamber status : 2 rows inserted, 2 reported\\n2025-01-15T03:42:21.570858090\\nCommand MODINFO received.\\n.\\n. 생략\\n.\\nTask ID: 10018__2025-01-10T01:51:55Z\\nTask ID: 10018__2025-01-10T01:51:55Z\\nCycler status : 8 rows inserted, 8 reported\\nNo is_parallel, Status -> Satus, TaskName as testname?\\n```\\n\\n위와 같이 데이타가 들어오는 과정이 보이지 않을 경우, kafka-subscriber 가 실행중인지 확인합니다.\\n```bash\\ndocker ps -a | grep kafka-subscriber\\n```\\n\\n만약 결과가 보이지 않으면 kafka-subscriber를 재시동 해봅니다.\\n```bash\\ndocker restart kafka-subscriber\\n```\\n\\n\\n## 서버별 실행 스크립트\\n\\n### Server 1 (~/installation/)\\n\\n.                                                                                \\n├── 1.prerequisite                                                               \\n│\\xa0\\xa0 └── install-docker.sh # 도커설치                                                       \\n├── 2.postgresql                                                                 \\n│\\xa0\\xa0 ├── run-as-active.sh  # Postgresql 실행 (Active)                                                       \\n│\\xa0\\xa0 └── run-as-standby.sh # Postgresql 실행 (Standby)                                                                  \\n├── 3.kafka                                                                      \\n│\\xa0\\xa0 └── run-kafka.sh  # 카프카 실행                                                           \\n├── 4.application                                                                \\n│\\xa0\\xa0 ├── check-version-client.sh # signet-client 버전체크(점검용)                                               \\n│\\xa0\\xa0 ├── check-version-server.sh # signet-server 버전체크(점검용)\\n│\\xa0\\xa0 ├── check-version-system.sh # signet-system 버전체크(점검용)                                                \\n│\\xa0\\xa0 └── run-server.sh  # Bife Cycler Application 실행                                                          \\n└── 5.subscriber                                                                 \\n    └── kafka-client.sh # Kafka subscriber 실행                                                         \\n\\n### Server 2 (~/installation/)\\n\\n.                                                                                \\n├── 1.prerequisite                                                               \\n│\\xa0\\xa0 └── install-docker.sh # 도커설치                                                       \\n├── 2.postgresql                                                                 \\n│\\xa0\\xa0 ├── run-as-active.sh  # Postgresql 실행 (Active)                                                       \\n│\\xa0\\xa0 └── run-as-standby.sh # Postgresql 실행 (Standby)                                                                  \\n├── 3.kafka                                                                      \\n│\\xa0\\xa0 └── run-kafka.sh  # 카프카 실행                                                           \\n├── 4.application                                                                \\n│\\xa0\\xa0 ├── check-version-client.sh # signet-client 버전체크(점검용)                                               \\n│\\xa0\\xa0 ├── check-version-server.sh # signet-server 버전체크(점검용)\\n│\\xa0\\xa0 ├── check-version-system.sh # signet-system 버전체크(점검용)                                                \\n│\\xa0\\xa0 └── run-server.sh  # Bife Cycler Application 실행                                                          \\n└── 5.subscriber                                                                 \\n    └── kafka-client.sh # Kafka subscriber 실행                                                         \\n                                                         \\n\\n### Server 3 (~/installation/)\\n.\\n├── 1.prerequisite\\n│\\xa0\\xa0 └── install-docker.sh # 도커설치\\n├── 2.postgresql\\n│\\xa0\\xa0 └── pgp.sh # postgresql pgpool-II 설치(monitoring)\\n└── 4.kafka\\n    └── run-kafka-3.sh (Kafka Client)   ']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Generated 1 clusters--\n"
     ]
    }
   ],
   "source": [
    "# 트리 구축\n",
    "leaf_texts = docs_texts  # 문서 텍스트를 리프 텍스트로 설정\n",
    "results = recursive_embed_cluster_summarize(\n",
    "    leaf_texts, level=1, n_levels=3\n",
    ")  # 재귀적으로 임베딩, 클러스터링 및 요약을 수행하여 결과를 얻음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (                                                text  \\\n",
       "  0  # BIFE-Cycler 설치/운영 매뉴얼\\n\\n어플리케이션의 설치를 위해서 필요한...   \n",
       "  \n",
       "                                                  embd cluster  \n",
       "  0  [0.004138216, 0.0005472095, 0.008901267, 0.003...     [0]  ,\n",
       "                                             summaries  level  cluster\n",
       "  0  It seems like you're experiencing some issues ...      1        0)}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# leaf_texts를 복사하여 all_texts를 초기화합니다.\n",
    "all_texts = leaf_texts.copy()\n",
    "\n",
    "# 각 레벨의 요약을 추출하여 all_texts에 추가하기 위해 결과를 순회합니다.\n",
    "for level in sorted(results.keys()):\n",
    "    # 현재 레벨의 DataFrame에서 요약을 추출합니다.\n",
    "    summaries = results[level][1][\"summaries\"].tolist()\n",
    "    # 현재 레벨의 요약을 all_texts에 추가합니다.\n",
    "    all_texts.extend(summaries)\n",
    "\n",
    "# 이제 all_texts를 사용하여 FAISS vectorstore를 구축합니다.\n",
    "vectorstore = FAISS.from_texts(texts=all_texts, embedding=embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DB_INDEX = \"RAPTOR\"\n",
    "\n",
    "# 로컬에 FAISS DB 인덱스가 이미 존재하는지 확인하고, 그렇다면 로드하여 vectorstore와 병합한 후 저장합니다.\n",
    "if os.path.exists(DB_INDEX):\n",
    "    local_index = FAISS.load_local(DB_INDEX, embeddings)\n",
    "    local_index.merge_from(vectorstore)\n",
    "    local_index.save_local(DB_INDEX)\n",
    "else:\n",
    "    vectorstore.save_local(folder_path=DB_INDEX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever 생성\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 프롬프트 생성\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# 문서 포스트 프로세싱\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    # 문서의 페이지 내용을 이어붙여 반환합니다.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# RAG 체인 정의\n",
    "rag_chain = (\n",
    "    # 검색 결과를 포맷팅하고 질문을 처리합니다.\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt  # 프롬프트를 적용합니다.\n",
    "    | model  # 모델을 적용합니다.\n",
    "    | StrOutputParser()  # 문자열 출력 파서를 적용합니다.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Docker 및 Kafka 관련 문제 해결에 대한 가이드입니다.\\n\\n1. **도커 컨테이너 이름 충돌**:\\n   - 도커 컨테이너를 실행할 때 이미 사용중인 이름으로 인해 오류가 발생하는 경우, 해당 컨테이너를 제거하거나 이름을 변경해야 합니다.\\n   - 제거 방법: `docker rm <컨테이너 이름>`\\n\\n2. **웹 브라우저 접속 문제**:\\n   - 로그 확인: `docker logs -f -n 1000 <인스턴스 이름>` 명령어를 사용하여 최근 로그를 확인합니다.\\n   - 로그 해석이 어려울 경우, 캡처본을 개발사에 전달합니다.\\n\\n3. **데이터가 들어오지 않는 경우**:\\n   - `kafka-subscriber`의 로그를 확인하여 데이터가 정상적으로 들어오는지 확인합니다.\\n   - `docker ps -a | grep kafka-subscriber` 명령어로 `kafka-subscriber` 컨테이너가 실행 중인지 확인합니다.\\n   - 재시동: `docker restart kafka-subscriber`\\n\\n4. **서버별 실행 스크립트**:\\n   - Server 1, Server 2, Server 3 각각의 설치 디렉토리 내에서 다양한 스크립트를 실행할 수 있습니다. \\n     - 예시: 도커 설치, PostgreSQL 실행, 카프카 실행, 애플리케이션 실행, 카프카 서브스크라이버 실행 등.\\n\\n이 가이드는 Docker와 Kafka 관련 문제 해결을 위한 기본적인 정보를 제공합니다. 자세한 내용이나 추가적인 도움이 필요할 경우 개발사나 전문가에게 상담하는 것이 좋습니다.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추상적인 질문 실행\n",
    "rag_chain.invoke(\"show servers for bife-cycler application\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.vectorstores import FAISS\n",
    "import faiss\n",
    "llm = OllamaLLM(model=\"llama3.3\")\n",
    "\n",
    "document_content_description = \"A guide to install and operation of a bife-cycler application.\"\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"manual\",\n",
    "        description=\"The manual of the bife-cycler application\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    # Additional metadata fields...\n",
    "]\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='5879a589-5f7e-4780-83f8-7cbfd7648e43', metadata={}, page_content='Docker 및 카프카(Kafka) 관련된 문제 해결을 위한 가이드입니다. 주요 내용은 다음과 같습니다.\\n\\n1. **도커 컨테이너 이름 충돌**:\\n   - 도커 컨테이너를 실행할 때 이미 사용중인 이름으로 인해 오류가 발생하는 경우, 해당 컨테이너를 제거하거나 이름을 변경해야 합니다.\\n   - 제거 방법: `docker rm <컨테이너 이름>`\\n\\n2. **웹 브라우저 접속 문제**:\\n   - 로그 확인: `docker logs -f -n 1000 <인스턴스 이름>` 명령어를 사용하여 최근 로그를 확인합니다.\\n   - 로그 해석이 어려울 경우, 캡처본을 개발사에 전달합니다.\\n\\n3. **데이터가 들어오지 않는 경우**:\\n   - `kafka-subscriber`의 로그를 확인하여 데이터가 정상적으로 들어오는지 확인합니다.\\n   - `docker ps -a | grep kafka-subscriber` 명령어로 `kafka-subscriber` 컨테이너가 실행 중인지 확인합니다.\\n   - 재시동: `docker restart kafka-subscriber`\\n\\n4. **서버별 실행 스크립트**:\\n   - Server 1, Server 2, Server 3 각각의 설치 디렉토리 내에서 다양한 스크립트를 실행할 수 있습니다. \\n     - 예시: 도커 설치, PostgreSQL 실행, 카프카 실행, 애플리케이션 실행, 카프카 서브스크라이버 실행 등.\\n\\n이 가이드는 Docker와 카프카 관련 문제 해결을 위한 기본적인 정보를 제공합니다. 자세한 내용이나 추가적인 도움이 필요할 경우 개발사나 전문가에게咨询하는 것이 좋습니다.'),\n",
       " Document(id='b2b06738-a00b-45b4-9bd4-33e65563cb71', metadata={}, page_content='# BIFE-Cycler 설치/운영 매뉴얼\\n\\n어플리케이션의 설치를 위해서 필요한 인프라 소프트웨어/서버를 설치합니다. 다음과 같은 순서로 설치합니다.\\n\\n참고로 운영서버는 다음과 같습니다.\\n\\nSignet Production Servers\\n=======================\\n\\n```\\n| Server      | Inner IP    |  Port   | OS Version         |\\n|-------------|-------------|---------|--------------------|\\n| server-1    | 192.168.0.11|  43011  | Ubuntu 24.04.1 LTS |\\n| server-2    | 192.168.0.12|  43012  | Ubuntu 24.04.1 LTS |\\n| server-3    | 192.168.0.13|  43013  | Ubuntu 24.04.1 LTS |\\n| server-4    | 192.168.0.14|  43014  | Ubuntu 24.04.1 LTS |\\n```\\n\\n설치 순서는 크게 6개의 단계로 나누어 집니다.\\n\\n- 환경준비\\n- 도커 설치\\n- DB 설치\\n- 카프카설치\\n- 어플리케이션 설치\\n- 카프카 클라이언트(데이터 수집) 설치\\n\\n\\n각 서버는 /(root)에 /data directory 를 다음과 같이 가지고 있습니다.\\n```bash \\n/data\\n├── config # 설정화일\\n│   └── kafka\\n│       └── server.properties\\n├── db # postgresql data 저장소\\n│   └── pgdata\\n│       ├── conf\\n│       │   ├── pg_hba.conf\\n│       │   └── postgresql.conf\\n│       ├── data  [error opening dir]\\n│       └── lock\\n│           └── master.lock\\n└── kafka # kafka 데이터 저장소\\n    ├── data\\n    │   ├── data\\n    │   └── meta\\n    └── logs\\n```\\n\\n아래에 순서대로 설치 방법을 기술합니다.\\n\\n## 1. Docker 설치\\n\\n모든 서버에 도커를 설치해야 합니다. 본 어플리케이션은 Docker 기반으로 운영됩니다.\\n먼저, Ubuntu Server 20.04 LTS에서 도커를 설치하는 방법을 안내합니다.\\n\\n### Step 1: Update your system\\n\\n소프트웨어를 설치하기 전에 패키지 목록이 최신인지 확인하는 것이 좋습니다. 다음 명령어로 수행할 수 있습니다:\\n```\\nsudo apt-get update\\nsudo apt-get install ca-certificates curl\\n```\\n### Step 2: Install Docker Engine on Ubuntu Server\\n\\n도커를 아래와 같이 설치합니다.\\n\\n```bash\\ncd installation\\ncd 1.prerequisites\\n./install-docker.sh \\n```\\n\\ninstall-docker.sh 의 내용은 아래와 같습니다.\\n\\n```bash\\n# Add Docker\\'s official GPG key:\\nsudo install -m 0755 -d /etc/apt/keyrings \\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\\nsudo chmod a+r /etc/apt/keyrings/docker.asc\\n\\n# Add the repository to Apt sources:\\necho \\\\\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\\\\n  $(. /etc/os-release && echo \"$VERSION_CODENAME\") stable\" | \\\\\\n  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\\nsudo apt-get update\\n\\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\\nsudo docker run hello-world # optional\\nsudo usermod -aG docker $USER\\n\\n```\\n***\\n###\\n\\n\\n## 2. Database 설치 및 실행\\n\\n먼저 DB를 저장하기 위한 데이터 저장소를 준비합니다. (1번/2번 서버에 적용)\\n이는 Docker 기반의 DB가 restart 되더라도 data를 유지하기 위함입니다.\\n\\n### Data 저장소 구성\\n\\n```bash\\ncd /\\nmkdir data\\ncd data\\nmkdir db\\n```\\n\\n저장소가 만들어 지면 이를 이용하여 postgresql을 실행합니다. \\n서버 1/2 에 postgresql의 저장소가 만들어 지며, 서버 3은 DB의 이상유무를 탐지하기 위한 repmgr를 사용합니다. 이를 통해 서버 1 또는 2에서 이상유무가 발견되면 자동으로 Failover(Standby -> Primary) 전환이 일어납니다.\\n\\n각각의 서버에 DB를 설치하기 위한 명령어는 다음과 같습니다.\\n\\n```bash\\ncd ~/installation/2.postgresql\\n./run-as-active.sh \\n```\\n\\n#### ~/installation/2.postgresql/run-as-active.sh\\n```bash\\ndocker run -p 5432:5432 -d --name pg-0  \\\\\\n --log-driver=json-file --log-opt max-size=10m --log-opt max-file=5 \\\\\\n -v /data/db/pgdata:/bitnami/postgresql \\\\\\n --env TZ=Asia/Seoul \\\\\\n --env REPMGR_PARTNER_NODES=pg-0,pg-1 \\\\\\n --env REPMGR_NODE_NAME=pg-0 \\\\\\n --env REPMGR_NODE_NETWORK_NAME=192.168.0.11  \\\\\\n --env REPMGR_PRIMARY_HOST=192.168.0.11 \\\\\\n --env REPMGR_PASSWORD=repmgrpass   \\\\\\n --env POSTGRESQL_POSTGRES_PASSWORD=Skcc12345678! \\\\\\n --env POSTGRESQL_USERNAME=signet \\\\\\n --env POSTGRESQL_DATABASE=signet \\\\\\n --env POSTGRESQL_PASSWORD=Signet12345678! \\\\\\n bitnami/postgresql-repmgr:latest\\n```\\n\\n아래의 명령은 Server 1이 Down되었을 경우, Server 2가 Primary로 전환되는 데, 이후 Server 1을 복구하였을 때이를 Standby로 실행하기 위한 스크립트입니다. \\n\\n```bash\\ncd ~/installation/2.postgresql\\n./run-as-standby.sh\\n```\\n\\n`REPMGR_PRIMARY_HOST`를 `192.168.0.12`로 지정하여 DB를 실행합니다. \\n\\n아래는 `run-as-standby.sh`의 내용입니다.\\n\\n```bash\\n# ~/installation/2.postgresql/run-as-standby.sh\\ndocker run -p 5432:5432 -d --name pg-0  \\\\\\n --log-driver=json-file --log-opt max-size=10m --log-opt max-file=5 \\\\\\n -v /data/db/pgdata:/bitnami/postgresql \\\\\\n --env TZ=Asia/Seoul \\\\\\n --env REPMGR_PARTNER_NODES=pg-0,pg-1 \\\\\\n --env REPMGR_NODE_NAME=pg-0 \\\\\\n --env REPMGR_NODE_NETWORK_NAME=192.168.0.11  \\\\\\n --env REPMGR_PRIMARY_HOST=192.168.0.12 \\\\\\n --env REPMGR_PASSWORD=repmgrpass   \\\\\\n --env POSTGRESQL_POSTGRES_PASSWORD=Skcc12345678! \\\\\\n --env POSTGRESQL_USERNAME=signet \\\\\\n --env POSTGRESQL_DATABASE=signet \\\\\\n --env POSTGRESQL_PASSWORD=Signet12345678! \\\\\\n bitnami/postgresql-repmgr:latest\\n```\\n\\n정상적으로 실행되었을 경우 다음과 같은 화면을 확인할 수 있습니다. \\n\\n(아래 pg-1이 standby 로 접속되었다는 것은 server-2, server-3 에 각각 pg-1, pgp 를 실행하고 난 뒤 확인할 수 있습니다.)\\n\\n```bash\\nkcl@kcl-1:~$ docker logs -f -n 100 pg-0\\npostgresql-repmgr 13:26:44.93 INFO  ==>\\npostgresql-repmgr 13:26:44.93 INFO  ==> Welcome to the Bitnami postgresql-repmgr container\\npostgresql-repmgr 13:26:44.93 INFO  ==> Subscribe to project updates by watching https://github.com/bitnami/containers\\npostgresql-repmgr 13:26:44.93 INFO  ==> Submit issues and feature requests at https://github.com/bitnami/containers/issues\\npostgresql-repmgr 13:26:44.94 INFO  ==> Upgrade to Tanzu Application Catalog for production environments to access custom-configured and pre-packaged software components. Gain enhanced features, including Software Bill of Materials (SBOM), CVE scan result reports, and VEX documents. To learn more, visit https://bitnami.com/enterprise\\npostgresql-repmgr 13:26:44.94 INFO  ==>\\npostgresql-repmgr 13:26:44.95 INFO  ==> ** Starting PostgreSQL with Replication Manager setup **\\npostgresql-repmgr 13:26:44.96 INFO  ==> Validating settings in REPMGR_* env vars...\\npostgresql-repmgr 13:26:44.97 INFO  ==> Validating settings in POSTGRESQL_* env vars..\\npostgresql-repmgr 13:26:44.97 INFO  ==> Querying all partner nodes for common upstream node...\\npostgresql-repmgr 13:26:45.00 INFO  ==> This node was acting as a primary before restart!\\npostgresql-repmgr 13:26:45.00 INFO  ==> Can not find new primary. Starting PostgreSQL normally...\\npostgresql-repmgr 13:26:45.00 INFO  ==> There are no nodes with primary role. Assuming the primary role...\\npostgresql-repmgr 13:26:45.00 INFO  ==> Preparing PostgreSQL configuration...\\npostgresql-repmgr 13:26:45.01 INFO  ==> postgresql.conf file not detected. Generating it...\\npostgresql-repmgr 13:26:45.05 INFO  ==> Preparing repmgr configuration...\\npostgresql-repmgr 13:26:45.06 INFO  ==> Initializing Repmgr...\\npostgresql-repmgr 13:26:45.06 INFO  ==> Initializing PostgreSQL database...\\npostgresql-repmgr 13:26:45.07 INFO  ==> Custom configuration /opt/bitnami/postgresql/conf/postgresql.conf detected\\npostgresql-repmgr 13:26:45.07 INFO  ==> Custom configuration /opt/bitnami/postgresql/conf/pg_hba.conf detected\\npostgresql-repmgr 13:26:45.08 INFO  ==> Deploying PostgreSQL with persisted data...\\npostgresql-repmgr 13:26:45.10 INFO  ==> Configuring replication parameters\\npostgresql-repmgr 13:26:45.11 INFO  ==> Configuring fsync\\n\\npostgresql-repmgr 13:26:45.12 INFO  ==> ** PostgreSQL with Replication Manager setup finished! **\\npostgresql-repmgr 13:26:45.14 INFO  ==> Starting PostgreSQL in background...\\npg_ctl: another server might be running; trying to start server anyway\\nserver starting\\n2025-01-14 04:26:45.165 GMT [143] LOG:  pgaudit extension initialized\\n2025-01-14 04:26:45.171 GMT [143] LOG:  redirecting log output to logging collector process\\n2025-01-14 04:26:45.171 GMT [143] HINT:  Future log output will appear in directory \"/opt/bitnami/postgresql/logs\".\\n2025-01-14 04:26:45.171 GMT [143] LOG:  starting PostgreSQL 16.4 on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit\\n2025-01-14 04:26:45.172 GMT [143] LOG:  listening on IPv4 address \"0.0.0.0\", port 5432\\n2025-01-14 04:26:45.172 GMT [143] LOG:  listening on IPv6 address \"::\", port 5432\\n2025-01-14 04:26:45.174 GMT [143] LOG:  listening on Unix socket \"/tmp/.s.PGSQL.5432\"\\n2025-01-14 04:26:45.178 GMT [149] LOG:  database system was interrupted; last known up at 2025-01-13 05:30:40 GMT\\n2025-01-14 04:26:45.188 GMT [149] LOG:  database system was not properly shut down; automatic recovery in progress\\n2025-01-14 04:26:45.192 GMT [149] LOG:  invalid record length at 0/1E1D17B0: expected at least 24, got 0\\n2025-01-14 04:26:45.192 GMT [149] LOG:  redo is not required\\n2025-01-14 04:26:45.194 GMT [147] LOG:  checkpoint starting: end-of-recovery immediate wait\\n2025-01-14 04:26:45.199 GMT [147] LOG:  checkpoint complete: wrote 3 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.002 s, sync=0.001 s, total=0.006 s; sync files=2, longest=0.001 s, average=0.001 s; distance=0 kB, estimate=0 kB; lsn=0/1E1D17B0, redo lsn=0/1E1D17B0\\n2025-01-14 04:26:45.202 GMT [143] LOG:  database system is ready to accept connections\\npostgresql-repmgr 13:26:46.16 INFO  ==> ** Starting repmgrd **\\n[2025-01-14 13:26:46] [NOTICE] repmgrd (repmgrd 5.4.1) starting up\\nINFO:  set_repmgrd_pid(): provided pidfile is /tmp/repmgrd.pid\\n[2025-01-14 13:26:46] [NOTICE] starting monitoring of node \"pg-0\" (ID: 1000)\\n[2025-01-14 13:26:46] [NOTICE] monitoring cluster primary \"pg-0\" (ID: 1000)\\n2025-01-14 04:28:10.168 GMT [147] LOG:  checkpoint starting: immediate force wait\\n2025-01-14 04:28:10.243 GMT [147] LOG:  checkpoint complete: wrote 2 buffers (0.0%); 0 WAL file(s) added, 1 removed, 0 recycled; write=0.012 s, sync=0.022 s, total=0.076 s; sync files=2, longest=0.017 s, average=0.011 s; distance=14522 kB, estimate=14522 kB; lsn=0/1F000060, redo lsn=0/1F000028\\n[2025-01-14 13:28:16] [NOTICE] new standby \"pg-1\" (ID: 1001) has connected\\n```\\n\\n다음은 Server 2에 DB를 실행할 때는 Standby 모드로 실행합니다. 이는 REPMGR_PRIMARY_HOST를 서버 1(192.168.0.11)로 지정함으로 Standby 모드로 진입합니다.\\n\\n```bash\\nssh kcl@192.168.0.12 # kcl2 서버로 로그인\\ncd ~/installation/2.postgresql\\n./run-as-standby.sh\\n```\\n\\n아래는 `run-as-standby.sh`의 내용입니다.\\n\\n```bash\\n# ~/installation/2.postgresql/run-as-standby.sh\\ndocker run -p 5432:5432 -d --name pg-1  \\\\\\n --log-driver=json-file --log-opt max-size=10m --log-opt max-file=5 \\\\\\n -v /data/db/pgdata:/bitnami/postgresql \\\\\\n --env TZ=Asia/Seoul \\\\\\n --env REPMGR_PARTNER_NODES=pg-0,pg-1 \\\\\\n --env REPMGR_NODE_NAME=pg-1 \\\\\\n --env REPMGR_NODE_NETWORK_NAME=192.168.0.12  \\\\\\n --env REPMGR_PRIMARY_HOST=192.168.0.11 \\\\\\n --env REPMGR_PASSWORD=repmgrpass   \\\\\\n --env POSTGRESQL_POSTGRES_PASSWORD=Skcc12345678! \\\\\\n --env POSTGRESQL_USERNAME=signet \\\\\\n --env POSTGRESQL_DATABASE=signet \\\\\\n --env POSTGRESQL_PASSWORD=Signet12345678! \\\\\\n bitnami/postgresql-repmgr:latest\\n```\\n\\n만약 Server 2 를 Primary 로 실행하기 위해서는 `run-as-active.sh`을 실행합니다.\\n\\n```bash\\n# ~/installation/2.postgresql/run-as-active.sh\\ndocker run -p 5432:5432 -d --name pg-0  \\\\\\n --log-driver=json-file --log-opt max-size=10m --log-opt max-file=5 \\\\\\n -v /data/db/pgdata:/bitnami/postgresql \\\\\\n --env TZ=Asia/Seoul \\\\\\n --env REPMGR_PARTNER_NODES=pg-0,pg-1 \\\\\\n --env REPMGR_NODE_NAME=pg-1 \\\\\\n --env REPMGR_NODE_NETWORK_NAME=192.168.0.12  \\\\\\n --env REPMGR_PRIMARY_HOST=192.168.0.12 \\\\\\n --env REPMGR_PASSWORD=repmgrpass   \\\\\\n --env POSTGRESQL_POSTGRES_PASSWORD=Skcc12345678! \\\\\\n --env POSTGRESQL_USERNAME=signet \\\\\\n --env POSTGRESQL_DATABASE=signet \\\\\\n --env POSTGRESQL_PASSWORD=Signet12345678! \\\\\\n bitnami/postgresql-repmgr:latest\\n```\\n\\n이상과 같이 설치를 하고 난뒤 `docker ps`를 실행하여 보면 다음과 같이 실행되어 있는 것을 볼 수 있습니다.\\n\\n```bash\\n\\nkcl@kcl-2:~/installation/2.postgresql$ docker ps\\nCONTAINER ID   IMAGE                              COMMAND                  CREATED         STATUS         PORTS                                                           NAMES\\nbfa5af3e6431   bitnami/postgresql-repmgr:latest   \"/opt/bitnami/script…\"   2 seconds ago   Up 2 seconds   0.0.0.0:5432->5432/tcp, :::5432->5432/tcp                       pg-1 \\n\\nkcl@kcl-2:~/installation/2.postgresql$ docker logs -f -n 100 pg-1\\npostgresql-repmgr 13:00:15.83 INFO  ==>\\npostgresql-repmgr 13:00:15.83 INFO  ==> Welcome to the Bitnami postgresql-repmgr container\\npostgresql-repmgr 13:00:15.83 INFO  ==> Subscribe to project updates by watching https://github.com/bitnami/containers\\npostgresql-repmgr 13:00:15.83 INFO  ==> Submit issues and feature requests at https://github.com/bitnami/containers/issues\\npostgresql-repmgr 13:00:15.83 INFO  ==> Upgrade to Tanzu Application Catalog for production environments to access custom-configured and pre-packaged software components. Gain enhanced features, including Software Bill of Materials (SBOM), CVE scan result reports, and VEX documents. To learn more, visit https://bitnami.com/enterprise\\npostgresql-repmgr 13:00:15.84 INFO  ==>\\npostgresql-repmgr 13:00:15.85 INFO  ==> ** Starting PostgreSQL with Replication Manager setup **\\npostgresql-repmgr 13:00:15.87 INFO  ==> Validating settings in REPMGR_* env vars...\\npostgresql-repmgr 13:00:15.87 INFO  ==> Validating settings in POSTGRESQL_* env vars..\\npostgresql-repmgr 13:00:15.87 INFO  ==> Querying all partner nodes for common upstream node...\\npostgresql-repmgr 13:00:15.93 INFO  ==> Node configured as standby\\npostgresql-repmgr 13:00:15.93 INFO  ==> Preparing PostgreSQL configuration...\\npostgresql-repmgr 13:00:15.93 INFO  ==> postgresql.conf file not detected. Generating it...\\npostgresql-repmgr 13:00:15.98 INFO  ==> Preparing repmgr configuration...\\npostgresql-repmgr 13:00:15.99 INFO  ==> Initializing Repmgr...\\npostgresql-repmgr 13:00:15.99 INFO  ==> Waiting for primary node...\\n```\\n\\nDB 구성의 마지막으로 Server-3 에서 REPMGR 을 설치합니다. \\n\\n```bash\\ncd ~/installation/2.postgresql\\n./pgp.sh\\n```\\n\\n위의 프로그램은 Server-1, Server-2 에 있는 DB를 모니터링하고, 문제가 발생하였을 때 이를 자동으로  Failover 해 주는 용도입니다.\\n\\n또한, DB 커넥션을 현재 Active 인 DB로 맺어주는 역할을 합니다. 그러므로 Application 또는 DB Client 는 Server-1, Server-2 에 개별로 접속하지 않고 `192.168.0.13` 를 이용하여 접속합니다.\\n\\n상기 `pgp.sh`의 내용은 다음과 같습니다.\\n\\n```bash\\nkcl@kcl-dev:~/installation/2.postgresql$ cat pgp.sh\\ndocker run --restart always -p 6532:5432 --log-driver=json-file --log-opt max-size=10m --log-opt max-file=5  \\\\\\n        --network=host \\\\\\n        -d --name pgp1 \\\\\\n--env PGPOOL_AUTO_FAILBACK=yes   \\\\\\n--env PGPOOL_BACKEND_APPLICATION_NAMES=pg-0,pg-1  \\\\\\n--env PGPOOL_BACKEND_NODES=0:pg-0:5432,1:pg-1:5432 \\\\\\n--env PGPOOL_SR_CHECK_USER=postgres \\\\\\n--env PGPOOL_SR_CHECK_PASSWORD=Skcc12345678! \\\\\\n--env PGPOOL_NUM_INIT_CHILDREN=64 \\\\\\n--env PGPOOL_POSTGRES_USERNAME=signet    \\\\\\n--env PGPOOL_POSTGRES_PASSWORD=Signet12345678!    \\\\\\n--env PGPOOL_ADMIN_USERNAME=pgpadmin    \\\\\\n--env PGPOOL_ADMIN_PASSWORD=Skcc12345678! bitnami/pgpool:latest   \\n```\\n\\n정상 실행되었는지의 여부를 `docker logs -f pgp1`을 통해서 다음과 같이 확인할 수 있습니다.\\n\\n```bash\\nkcl@kcl-dev:~/installation/2.postgresql$ docker logs -f pgp1\\npgpool 04:43:47.29 INFO  ==>\\npgpool 04:43:47.29 INFO  ==> Welcome to the Bitnami pgpool container\\npgpool 04:43:47.29 INFO  ==> Subscribe to project updates by watching https://github.com/bitnami/containers\\npgpool 04:43:47.29 INFO  ==> Submit issues and feature requests at https://github.com/bitnami/containers/issues\\npgpool 04:43:47.29 INFO  ==> Upgrade to Tanzu Application Catalog for production environments to access custom-configured and pre-packaged software components. Gain enhanced features, including Software Bill of Materials (SBOM), CVE scan result reports, and VEX documents. To learn more, visit https://bitnami.com/enterprise\\npgpool 04:43:47.29 INFO  ==>\\npgpool 04:43:47.30 INFO  ==> ** Starting Pgpool-II setup **\\npgpool 04:43:47.32 INFO  ==> Validating settings in PGPOOL_* env vars...\\npgpool 04:43:47.33 INFO  ==> Initializing Pgpool-II...\\npgpool 04:43:47.33 INFO  ==> Generating pg_hba.conf file...\\npgpool 04:43:47.33 INFO  ==> Generating pgpool.conf file...\\npgpool 04:43:47.42 INFO  ==> Generating password file for local authentication...\\npgpool 04:43:47.42 INFO  ==> Generating password file for pgpool admin user...\\npgpool 04:43:47.43 INFO  ==> ** Pgpool-II setup finished! **\\n\\npgpool 04:43:47.44 INFO  ==> ** Starting Pgpool-II **\\n2025-01-14 04:43:47.454: main pid 1: LOG:  Backend status file /opt/bitnami/pgpool/logs/pgpool_status does not exist\\n2025-01-14 04:43:47.454: main pid 1: LOG:  health_check_stats_shared_memory_size: requested size: 12288\\n2025-01-14 04:43:47.454: main pid 1: LOG:  memory cache initialized\\n2025-01-14 04:43:47.454: main pid 1: DETAIL:  memcache blocks :64\\n2025-01-14 04:43:47.454: main pid 1: LOG:  allocating (144190784) bytes of shared memory segment\\n2025-01-14 04:43:47.455: main pid 1: LOG:  allocating shared memory segment of size: 144190784\\n2025-01-14 04:43:47.517: main pid 1: LOG:  health_check_stats_shared_memory_size: requested size: 12288\\n2025-01-14 04:43:47.517: main pid 1: LOG:  health_check_stats_shared_memory_size: requested size: 12288\\n2025-01-14 04:43:47.517: main pid 1: LOG:  memory cache initialized\\n2025-01-14 04:43:47.517: main pid 1: DETAIL:  memcache blocks :64\\n2025-01-14 04:43:47.518: main pid 1: LOG:  pool_discard_oid_maps: discarded memqcache oid maps\\n2025-01-14 04:43:47.529: main pid 1: LOG:  create socket files[0]: /opt/bitnami/pgpool/tmp/.s.PGSQL.5432\\n2025-01-14 04:43:47.529: main pid 1: LOG:  listen address[0]: *\\n2025-01-14 04:43:47.529: main pid 1: LOG:  Setting up socket for 0.0.0.0:5432\\n2025-01-14 04:43:47.529: main pid 1: LOG:  Setting up socket for :::5432\\n2025-01-14 04:43:47.534: main pid 1: LOG:  find_primary_node_repeatedly: waiting for finding a primary node\\n2025-01-14 04:43:47.573: main pid 1: LOG:  find_primary_node: primary node is 0\\n2025-01-14 04:43:47.573: main pid 1: LOG:  find_primary_node: standby node is 1\\n2025-01-14 04:43:47.573: main pid 1: LOG:  create socket files[0]: /opt/bitnami/pgpool/tmp/.s.PGSQL.9898\\n2025-01-14 04:43:47.573: main pid 1: LOG:  listen address[0]: localhost\\n2025-01-14 04:43:47.574: main pid 1: LOG:  Setting up socket for ::1:9898\\n2025-01-14 04:43:47.574: main pid 1: LOG:  Setting up socket for 127.0.0.1:9898\\n2025-01-14 04:43:47.574: pcp_main pid 174: LOG:  PCP process: 174 started\\n2025-01-14 04:43:47.574: sr_check_worker pid 175: LOG:  process started\\n2025-01-14 04:43:47.574: health_check pid 176: LOG:  process started\\n2025-01-14 04:43:47.574: health_check pid 177: LOG:  process started\\n2025-01-14 04:43:47.575: main pid 1: LOG:  pgpool-II successfully started. version 4.5.4 (hotooriboshi)\\n2025-01-14 04:43:47.575: main pid 1: LOG:  node status[0]: 1\\n2025-01-14 04:43:47.575: main pid 1: LOG:  node status[1]: 2\\n\\n```\\n## 3. Kafka 설치\\n\\nkafka 설정을 저장하기 위하여 다음의 경로를 작성합니다. 카프카의 설정은 1/2/3 번 서버 모두 `/data/config/kafka/server.properties`에 저장됩니다.\\n\\n```bash\\n# /data/config/kafka\\ncd /data\\nmkdir config\\ncd config\\nmkdir kafka\\ncd kafka\\n\\n```\\n\\n그리고 `vi server.properties` 를 실행하여 아래의 내용을 저장합니다.\\n`/data/config/kafka/server.properties` 의 내용은 다음과 같습니다. \\n\\n(2, 3번은 node.id 와 advertised.listener 를 변경하여 적용합니다.)\\n\\n```bash\\n# Broker ID - must be unique across all brokers\\nnode.id=1 # 2, 3 for 192.168.0.12, 192.168.0.13\\n\\n# The directory where Kafka will store logs, including metadata logs\\nlog.dirs=/var/lib/kafka/data\\n\\n# Enable KRaft mode by setting the process.roles property\\n# Setting the role to \\'broker,controller\\' means this node acts as both a broker and a controller\\nprocess.roles=broker,controller\\n\\n# The address the broker should bind to\\nlistener.security.protocol.map=PLAINTEXT_LOCAL:PLAINTEXT,PLAINTEXT_TUNNEL:PLAINTEXT,CONTROLLER:PLAINTEXT\\nlisteners=PLAINTEXT_TUNNEL://0.0.0.0:9094,PLAINTEXT_LOCAL://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093\\n#advertised.listeners=PLAINTEXT://kcl1.signet:9092\\nadvertised.listeners=PLAINTEXT_TUNNEL://localhost:9094,PLAINTEXT_LOCAL://192.168.0.11:9092 # node2 => 192.168.0.12, node3 => 192.168.0.13 으로 변경\\n# The address the controller should bind to (use different ports if necessary)\\ncontroller.listener.names=CONTROLLER\\n# listener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT\\ninter.broker.listener.name=PLAINTEXT_LOCAL\\n\\n# Quorum Voters - list of all brokers eligible to participate in the quorum (node.id@address)\\n# Include all brokers that are part of the KRaft quorum\\ncontroller.quorum.voters=1@192.168.0.11:9093,2@192.168.0.12:9093,3@192.168.0.13:9093\\n\\n# Log settings\\nlog.retention.hours=168\\nlog.segment.bytes=1073741824\\n\\n# Other configurations (adjust as necessary)\\nnum.network.threads=3\\nnum.io.threads=8\\nsocket.send.buffer.bytes=102400\\nsocket.receive.buffer.bytes=102400\\nsocket.request.max.bytes=104857600\\n\\nmax.message.bytes=104857600  # 100 MB\\n# producer config => max.request.size=104857600\\n# consumer config => max.partition.fetch.bytes=104857600\\n\\n# Zookeeper settings are not required in KRaft mode, ensure any Zookeeper-related configs are removed or commented out\\n# zookeeper.connect=localhost:2181\\n\\n# Metadata storage directory\\nmetadata.log.dir=/var/lib/kafka/meta\\n\\n# Specify the initial broker quorum replication factor\\n# Generally, this should be at least 3 for production setups\\noffsets.topic.replication.factor=3\\ntransaction.state.log.replication.factor=3\\ntransaction.state.log.min.isr=2\\n\\n\\n# Miscellaneous settings\\nauto.create.topics.enable=false\\ndelete.topic.enable=true\\ndefault.replication.factor=3\\n```\\n\\n위와 같이 kafka 구성을 저장한뒤 다음의 명령어를 통하여 kafka를 실행합니다. (1,2,3 번 서버각각 실행)\\n```bash\\ncd ~/installation/2.kafka/run-kafka.sh\\n```\\n\\n참고로 위의 스크립트의 내용은 아래와 같습니다.\\n\\n```bash\\ndocker run --name kafka-1 -d --restart always \\\\\\n-p 9092:9092 -p 9093:9093 -p 9094:9094 \\\\\\n-v /data/config/kafka:/mnt/shared/config \\\\\\n-v /data/kafka/data:/var/lib/kafka \\\\\\n-v /data/kafka/logs:/var/log/kafka \\\\\\n--log-driver=json-file --log-opt max-size=10m --log-opt max-file=20 \\\\\\napache/kafka:latest\\n```\\n\\n정상적으로 실행되었을 경우 `docker ps`를 실행하였을 때 다음과 같은 메세지를 확인할 수 있습니다.\\n\\n```bash\\n# 카프카 instance 생성 여부 확인\\nkcl@kcl-2:~/installation/3.kafka$ docker ps\\nCONTAINER ID   IMAGE                 COMMAND                  CREATED      STATUS      PORTS                                                           NAMES\\nfe3bcafcfbcf   apache/kafka:latest   \"/__cacert_entrypoin…\"   7 days ago   Up 3 days   0.0.0.0:9092-9094->9092-9094/tcp, :::9092-9094->9092-9094/tcp   kafka-2\\n\\n# 카프카 정상실행 여부 확인\\nkcl@kcl-2:~/installation/3.kafka$ docker logs -f kafka-2 | more\\n===> User\\nuid=1000(appuser) gid=1000(appuser) groups=1000(appuser)\\n===> Setting default values of environment variables if not already set.\\nCLUSTER_ID not set. Setting it to default value: \"5L6g3nShT-eMCtK--X86sw\"\\n===> Configuring ...\\n===> Launching ...\\n===> Using provided cluster id 5L6g3nShT-eMCtK--X86sw ...\\n[2025-01-07 04:36:54,020] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)\\n[2025-01-07 04:36:54,056] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util) [2025-01-07 04:36:54,057] INFO RemoteLogManagerConfig values:\\n        log.local.retention.bytes = -2\\n        log.local.retention.ms = -2\\n        remote.fetch.max.wait.ms = 500\\n        remote.log.index.file.cache.total.size.bytes = 1073741824\\n        remote.log.manager.copier.thread.pool.size = 10\\n        remote.log.manager.copy.max.bytes.per.second = 9223372036854775807\\n        remote.log.manager.copy.quota.window.num = 11\\n        remote.log.manager.copy.quota.window.size.seconds = 1\\n        remote.log.manager.expiration.thread.pool.size = 10\\n        remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807\\n        remote.log.manager.fetch.quota.window.num = 11\\n        remote.log.manager.fetch.quota.window.size.seconds = 1\\n        remote.log.manager.task.interval.ms = 30000\\n        remote.log.manager.task.retry.backoff.max.ms = 30000\\n        remote.log.manager.task.retry.backoff.ms = 500\\n        remote.log.manager.task.retry.jitter = 0.2\\n        remote.log.manager.thread.pool.size = 10\\n        remote.log.metadata.custom.metadata.max.bytes = 128\\n        remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager\\n        remote.log.metadata.manager.class.path = null\\n        remote.log.metadata.manager.impl.prefix = rlmm.config.\\n        remote.log.metadata.manager.listener.name = null\\n        remote.log.reader.max.pending.tasks = 100\\n        remote.log.reader.threads = 10\\n        remote.log.storage.manager.class.name = null\\n        remote.log.storage.manager.class.path = null\\n        remote.log.storage.manager.impl.prefix = rsm.config.\\n        remote.log.storage.system.enable = false\\n```\\n\\n\\n만약 SSL 통신을 위하여는 java의 keytool을 이용하여 다음과 같이 SSL 인증서를 생성하여 설정합니다.\\n\\n```bash\\nsudo apt install openjdk-17-jre-headless                                                                     \\nmkdir keys                                                                                                   \\ncd keys/                                                                                                     \\nkeytool -genkeypair -alias ca -keyalg RSA -keysize 2048 -storetype PKCS12 \\\\\\n   -keystore ca.p12 -validity 365 -dname \"CN=KafkaCA, OU=None, O=None, L=None, S=None, C=None\"   -ext bc:c\\n \\nkeytool -export -alias ca -file ca.crt -keystore ca.p12\\nkeytool -genkeypair -alias kafka-server -keyalg RSA -keysize 2048 \\\\\\n  -storetype PKCS12 -keystore server.p12 -validity 365   -dname \"CN=kafka-broker, OU=None, O=None, L=None, S=None, C=None\"\\nkeytool -certreq -alias kafka-server -file server.csr -keystore server.p12\\nkeytool -gencert -validity 365 -alias ca -infile server.csr   -outfile server.crt -keystore ca.p12\\nkeytool -import -trustcacerts -alias ca -file ca.crt   -keystore server.p12\\nkeytool -import -alias kafka-server -file server.crt   -keystore server.p12\\nkeytool -import -alias ca -file ca.crt   -keystore client.truststore.p12\\nkeytool -genkeypair -alias kafka-client -keyalg RSA -keysize 2048 \\\\\\n  -storetype PKCS12 -keystore client.p12 -validity 365   -dname \"CN=kafka-client, OU=None, O=None, L=None, S=None, C=None\"\\n```\\n\\n\\n## 4. HAProxy 설치\\n\\n아래 HAProxy를 이용한 로드밸런싱 설정을 기술하였습니다. \\n\\n**중요) HAProxy 는 192.168.0.13 서버에 설정합니다.**\\n\\n```bash\\nsudo apt-get install haproxy\\ncd /etc/aproxy/                                                                                                  \\nsudo vi haproxy.cfg                                                                                               \\n```\\n\\nhaproxy.cfg 파일은 아래와 같이 설정합니다.\\n\\n\\n### /etc/haproxy.cfg\\n```bash\\nglobal\\n        log /dev/log    local0\\n        log /dev/log    local1 notice\\n        chroot /var/lib/haproxy\\n        stats socket /run/haproxy/admin.sock mode 660 level admin\\n        stats timeout 30s\\n        user haproxy\\n        group haproxy\\n        daemon\\n\\n        # Default SSL material locations\\n        ca-base /etc/ssl/certs\\n        crt-base /etc/ssl/private\\n\\n        # See: https://ssl-config.mozilla.org/#server=haproxy&server-version=2.0.3&config=intermediate\\n        ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\\n        ssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256\\n        ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets\\n\\ndefaults\\n        log     global\\n        mode    http\\n        option  httplog\\n        option  dontlognull\\n        timeout connect 5000\\n        timeout client  50000\\n        timeout server  50000\\n        errorfile 400 /etc/haproxy/errors/400.http\\n        errorfile 403 /etc/haproxy/errors/403.http\\n        errorfile 408 /etc/haproxy/errors/408.http\\n        errorfile 500 /etc/haproxy/errors/500.http\\n        errorfile 502 /etc/haproxy/errors/502.http\\n        errorfile 503 /etc/haproxy/errors/503.http\\n        errorfile 504 /etc/haproxy/errors/504.http\\n\\nfrontend signet_frontend\\n    bind *:80\\n    acl api_system_path path_beg -i /system/api\\n    acl api_signet_path path_beg -i /signet/api\\n\\n    use_backend api_system_server if api_system_path\\n    use_backend api_signet_server if api_signet_path\\n\\n    default_backend signet_client\\n\\nbackend signet_client\\n    server client1 192.168.0.11:8000\\n    server client2 192.168.0.12:8000\\n\\nbackend api_system_server\\n    http-request set-path \"%[path,regsub(^/system/api/,/api/)]\"\\n    server system_instance1 192.168.0.11:8003 # check\\n    server system_instance2 192.168.0.12:8003 # check\\n\\nbackend api_signet_server\\n    http-request set-path \"%[path,regsub(^/signet/api/,/api/)]\"\\n    server signet_instance1 192.168.0.11:8002 # check\\n    server signet_instance2 192.168.0.12:8002 # check\\n\\n```\\n\\n파일을 저장한 후 다음의 명령들을 실행하여 정상적으로 동작하는지의 여부를 확인합니다.\\n\\n```bash\\nkcl@kcl-dev:/etc/haproxy$ sudo systemctl restart haproxy.service\\nkcl@kcl-dev:/etc/haproxy$ sudo systemctl status haproxy.service\\n● haproxy.service - HAProxy Load Balancer\\n     Loaded: loaded (/usr/lib/systemd/system/haproxy.service; enabled; preset: enabled)\\n     Active: active (running) since Tue 2025-01-14 04:19:42 UTC; 7s ago\\n       Docs: man:haproxy(1)\\n             file:/usr/share/doc/haproxy/configuration.txt.gz\\n   Main PID: 14682 (haproxy)\\n     Status: \"Ready.\"\\n      Tasks: 17 (limit: 38049)\\n     Memory: 43.6M (peak: 46.0M)\\n        CPU: 87ms\\n     CGroup: /system.slice/haproxy.service\\n             ├─14682 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock\\n             └─14686 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.sock\\n\\nJan 14 04:19:42 kcl-dev systemd[1]: Starting haproxy.service - HAProxy Load Balancer...\\nJan 14 04:19:42 kcl-dev haproxy[14682]: [NOTICE]   (14682) : New worker (14686) forked\\nJan 14 04:19:42 kcl-dev haproxy[14682]: [NOTICE]   (14682) : Loading success.\\nJan 14 04:19:42 kcl-dev systemd[1]: Started haproxy.service - HAProxy Load Balancer.\\nkcl@kcl-dev:/etc/haproxy$\\n```\\n\\n\\n## 4. Application 설치\\n\\nServer 1, Server 2 각각 메인 어플리케이션을 실행해 줍니다. \\n```bash\\ncd ~/installation/4.application\\n./run-server.sh\\n```\\n\\nrun-server.sh 의 내용은 다음과 같습니다.\\n\\n\\n```bash\\naws ecr get-login-password --region ap-northeast-2 | docker login --username AWS --password-stdin 511662517913.dkr.ecr.ap-northeast-2.amazonaws.com\\n\\ndocker stop signet-server\\ndocker stop signet-system\\ndocker rm signet-server\\ndocker rm signet-system\\n\\n# Signet Server\\nlatest_tag=$(aws ecr describe-images --repository-name signet/signet-server | \\\\\\n        jq -r \\'.imageDetails | sort_by(.imagePushedAt) | last(.[]).imageTags[0]\\')\\necho \"Latest signet-server version : $latest_tag\"\\ndocker run -it -d -p 8002:8080 --name signet-server \\\\\\n        -e DB_URL=jdbc:postgresql://192.168.0.13:5432/signet \\\\\\n        -e DB_USERNAME=signet \\\\\\n        -e DB_PASSWORD=Signet12345678! \\\\\\n        511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-server:$latest_tag\\n# Signet Base System\\nlatest_tag=$(aws ecr describe-images --repository-name signet/signet-system | \\\\\\n        jq -r \\'.imageDetails | sort_by(.imagePushedAt) | last(.[]).imageTags[0]\\')\\necho \"Latest signet-server version : $latest_tag\"\\ndocker run -it -d -p 8003:8080 --name signet-system \\\\\\n        -e DB_URL=jdbc:postgresql://192.168.0.13:5432/signet \\\\\\n        -e DB_USERNAME=signet \\\\\\n        -e DB_PASSWORD=Signet12345678! \\\\\\n        -e TOKEN_TIMEOUT=43200 \\\\\\n        511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-system:$latest_tag\\n\\n# Client\\nlatest_tag=$(aws ecr describe-images --repository-name signet/signet-client | \\\\\\n        jq -r \\'.imageDetails | sort_by(.imagePushedAt) | last(.[]).imageTags[0]\\')\\necho \"Latest version : $latest_tag\"\\ndocker stop signet-client1\\ndocker rm signet-client1\\ndocker run -it -d -p 8000:80 --name signet-client1 511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-client:$latest_tag\\n\\n```\\n\\n이후 `docker ps`를 통해 어플리케이션의 instance가 잘 실행되었는지 확인합니다.\\n\\n```bash\\n# Server-1 에서 다음과 같은 instance들을 확인 할 수 있습니다.\\nkcl@kcl-1:~/installation/4.application$ docker ps\\nCONTAINER ID   IMAGE                                                                         COMMAND                  CREATED          STATUS          PORTS\\n                                        NAMES\\n42e74449e860   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-client:v-8    \"/docker-entrypoint.…\"   2 minutes ago    Up 2 minutes    0.0.0.0:8000->80/tcp, [::]:8000->80/tcp                         signet-client1\\n75efdd12f2e9   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-system:v-8    \"java -jar app.jar\"      2 minutes ago    Up 2 minutes    0.0.0.0:8003->8080/tcp, [::]:8003->8080/tcp                     signet-system\\nb0bd44830771   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-server:v-95   \"java -jar app.jar\"      2 minutes ago    Up 2 minutes    0.0.0.0:8002->8080/tcp, [::]:8002->8080/tcp                     signet-server\\n402f84836f18   bitnami/postgresql-repmgr:latest                                              \"/opt/bitnami/script…\"   22 minutes ago   Up 22 minutes   0.0.0.0:5432->5432/tcp, :::5432->5432/tcp                       pg-0\\nda70b14a280b   apache/kafka:latest                                                           \"/__cacert_entrypoin…\"   7 days ago       Up 3 days       0.0.0.0:9092-9094->9092-9094/tcp, :::9092-9094->9092-9094/tcp   kafka-1\\n\\n# 로그를 확인하여 제대로 실행되었는지 확인합니다. 일반적으로 최초 실행시 제일 뒷 라인의\\n# Started SignetApplication in 11.441 seconds (process running for 11.853) 를 확인합니다.\\n\\nkcl@kcl-1:~/installation/4.application$ docker logs -f signet-server\\n\\n  .   ____          _            __ _ _\\n /\\\\\\\\ / ___\\'_ __ _ _(_)_ __  __ _ \\\\ \\\\ \\\\ \\\\\\n( ( )\\\\___ | \\'_ | \\'_| | \\'_ \\\\/ _` | \\\\ \\\\ \\\\ \\\\\\n \\\\\\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\\n  \\'  |____| .__|_| |_|_| |_\\\\__, | / / / /\\n =========|_|==============|___/=/_/_/_/\\n :: Spring Boot ::                (v3.2.4)\\n\\n.\\n. # 생략\\n.\\n\\n2025-01-14T04:47:17.615Z  INFO 1 --- [Signet Service] [           main] o.s.s.web.DefaultSecurityFilterChain     : Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@bb832f0, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@1cdb691a, org.springframework.security.web.context.SecurityContextHolderFilter@4cd6143c, org.springframework.security.web.header.HeaderWriterFilter@4b5e664f, org.springframework.web.filter.CorsFilter@14656be5, org.springframework.security.web.authentication.logout.LogoutFilter@4d356547, com.skcc.bife.common.security.filter.JwtAuthenticationFilter@66ab924, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@2ae63c84, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@4c6f451b, org.springframework.security.web.session.SessionManagementFilter@1ecd979e, org.springframework.security.web.access.ExceptionTranslationFilter@a6bd353, org.springframework.security.web.access.intercept.AuthorizationFilter@60c7726b]\\n2025-01-14T04:47:17.926Z  INFO 1 --- [Signet Service] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port 8080 (http) with context path \\'\\'\\n2025-01-14T04:47:17.938Z  INFO 1 --- [Signet Service] [           main] com.skcc.bife.SignetApplication          : Started SignetApplication in 11.441 seconds (process running for 11.853)\\n```\\n\\n## 5. Kafka Client 설치 및 실행\\n\\n마지막으로 Kafka Client를 실행하여 데이터 수집 준비를 합니다.\\n먼저 topic을 만들어 두기 위하여 make-topics.sh 을 실행합니다. 이를 통해 `signet-msg-topic` 을 생성합니다.\\n```bash\\ncd ~/installation/5.subscriber\\n./make-topics.sh\\n\\n# list-topics.sh 을 통해 다음의 토픽이 생성되어 있는지 확인합니다.\\nkcl@kcl-1:~/installation/5.subscriber$ ./list-topics.sh\\n__consumer_offsets\\nsignet-bin-topic\\nsignet-msg-topic\\n\\n```\\n\\n./kafka-client.sh 을 실행하여 데이터 수집 준비를 합니다.\\n```bash\\n./kafka-client.sh\\n\\n# 실행후 docker ps를 통해 \"kafka-subscriber\"가 실행되어 있는 것을 확인할 수 있습니다.\\n\\nkcl@kcl-1:~/installation/5.subscriber$ docker ps\\nCONTAINER ID   IMAGE                                                                                  COMMAND                  CREATED          STATUS          PORTS\\n                                                 NAMES\\n8368c4b45ca0   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-kafka-subscriber:v-5   \"java -jar app.jar\"      15 seconds ago   Up 14 seconds\\n                                                 kafka-subscriber\\n\\nkcl@kcl-1:~/installation/5.subscriber$ docker logs kafka-subscriber\\nKAFKA_TOPIC_NAME: signet-msg-topic\\nKAFKA_BIN_TOPIC_NAME: signet-bin-topic\\nDATABASE_URL: jdbc:postgresql://192.168.0.13:5432/signet\\nDATABASE_USER: signet\\nBOOTSTRAP_SERVERS: 192.168.0.11:9092,192.168.0.12:9092,192.168.0.13:9092\\nRECONNECT_DELAY_MS: 5000\\nSLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\\nSLF4J: Defaulting to no-operation (NOP) logger implementation\\nSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\\nListening to : [signet-msg-topic, signet-bin-topic]\\n\\n2025-01-14T05:17:28 : Connected to the database.                                                 \\n```\\n\\n참고로, `kafka-client.sh`의 내용은 다음과 같습니다.\\n\\n```bash\\naws ecr get-login-password --region ap-northeast-2 | docker login --username AWS --password-stdin 511662517913.dkr.ecr.ap-northeast-2.amazonaws.com\\n\\ndocker stop signet-kafka-subscriber\\ndocker rm signet-kafka-subscriber\\n\\nlatest_tag=$(aws ecr describe-images --repository-name signet/signet-kafka-subscriber | \\\\\\n        jq -r \\'.imageDetails | sort_by(.imagePushedAt) | last(.[]).imageTags[0]\\')\\necho \"Latest version : $latest_tag\"\\ndocker run -it -d --name signet-kafka-subscriber \\\\\\n    -e DATABASE_URL jdbc:postgresql://rds-bife-dev.cluster-ctw6ta8xocaf.ap-northeast-2.rds.amazonaws.com:5432/signet-dev \\\\\\n    -e DATABASE_USER signet \\\\\\n    -e DATABASE_PASSWORD Bife6400! \\\\\\n    -e KAFKA_TOPIC signet-msg-topic \\\\\\n    511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-kafka-subscriber:$latest_tag\\n\\n```\\n\\n## 6. HTTPS\\n\\nlet\\'s encrypt 와 certbot을 활용하여 https 통신시 \\n\\n```bash\\nsudo apt-get install certbot\\nsudo certbot certonly\\ncd /etc/letsencrypt/\\n```\\n\\n```bash\\nfrontend https\\n    bind *:443 ssl crt /etc/<your cert>/fullchain.pem.key\\n    mode http\\n    option forwardfor\\n    option httpchk GET /healthcheck\\n\\n    # Set default backend\\n    default_backend your-backend-name\\n```\\n\\n## 7. 운영시 참고 사항\\n\\n### 정상적인 동작 확인 방법\\n\\n\\n### 1. DB\\n\\n- DB의 서버중 한대에 이상이 발생하였을 시, 다음과 같은 조치를 취합니다.\\n\\n1. Primary 서버에 이상이 발생하였을 경우,\\n- 기존의 Standby 서버가 Primary 서버로 전환되므로, 이전의 Primary 서버를 다시 실행할 때 이를 Standby 모드로 실행합니다.\\n\\n2. Standby 서버에 이상이 발생하였을 경우,\\n- Standby 서버에 이상이 발생하였을 경우, Primary Server의 전환이 일어나지 않으로, 기존대로 Standby 서버로 실행합니다.\\n\\n### 2. Kafka\\n- 카프카의 문제가 발생시 새로이 실행함으로, 카프카의 노드를 KRaft 클러스터에 다시 참여 시킵니다.\\n\\n### 3. Application\\n\\n- 어플리케이션은 위에서 제공된 스크립트를 통해 최신버전을 항상 최신 버전을 실행할 수 있습니다.\\n- 어플리케이션의 재배포시 위의 스크립트를 실행함으로 최신버전을 실행할 수 있습니다. \\n\\n\\n\\n\\n## A. 어플리케이션 실행 (요약)\\n\\n1. DB (pg-0, pg-1, pgp)\\n\\n./installation/2.postgresql/run-as-active.sh (Server 1에서 Active 상태로 실행) \\n./installation/2.postgresql/run-as-standby.sh (Server 2에서 Standby 상태로 실행)\\n./installation/2.postgresql/pgp.sh\\n\\n2. Kafka\\n\\n2. Application (signet-system, signet-server, signet-client1)\\n\\ncd ~/installation/4.application \\n./run-server.sh \\n\\n3. Kafka Client (docker kafka-subscriber)\\n\\ncd ~/installation/5.subscriber\\n./kafka-client.sh \\n\\n\\n## B. 문제해결\\n\\n- 서버별 정상 작동 여부 확인\\n\\nServer-1 에서 docker ps를 실행하였을때 다음의 6개 docker container list가 보여야 정상 작동 됩니다.\\n\\nsignet-client1, signet-system, signet-server, pg-0, kafka-1, kafka-subscriber\\n\\n```bash\\nkcl@kcl-1$ docker ps\\nCONTAINER ID   IMAGE                                                                                  COMMAND\\n          CREATED          STATUS          PORTS                                                           NAMES\\n19fdffc0872f   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-kafka-subscriber:v-5   \"java -jar app.jar\"      16 seconds ago   Up 16 seconds                                                                   kafka-subscriber\\n40d9f3a2bfe3   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-client:v-8             \"/docker-entrypoint.…\"   2 hours ago      Up 2 hours      0.0.0.0:8000->80/tcp, [::]:8000->80/tcp                         signet-client1\\nd5905121ad38   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-system:v-10            \"java -jar app.jar\"      2 hours ago      Up 2 hours      0.0.0.0:8003->8080/tcp, [::]:8003->8080/tcp                     signet-system\\n012fb23819dc   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-server:v-99            \"java -jar app.jar\"      2 hours ago      Up 2 hours      0.0.0.0:8002->8080/tcp, [::]:8002->8080/tcp                     signet-server\\n181a6488b318   bitnami/postgresql-repmgr:latest                                                       \"/opt/bitnami/script…\"   3 hours ago      Up 3 hours                                                                      pg-0\\nda70b14a280b   apache/kafka:latest                                                                    \"/__cacert_entrypoin…\"   7 days ago       Up 4 days       0.0.0.0:9092-9094->9092-9094/tcp, :::9092-9094->9092-9094/tcp   kafka-1\\n\\n```\\n\\nServer-2\\n\\npg-1, kafka-2, signet-server, signet-system, signet-client, kafka-subscriber\\n\\n```bash\\nkcl@kcl-2:~/installation/5.subscriber$ docker ps\\nCONTAINER ID   IMAGE                                                                                  COMMAND\\n          CREATED          STATUS          PORTS                                                           NAMES\\n2926664eb4a1   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-kafka-subscriber:v-5   \"java -jar app.jar\"      11 seconds ago   Up 10 seconds                                                                   kafka-subscriber\\nb0328b7644a8   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-client:v-8             \"/docker-entrypoint.…\"   2 hours ago      Up 2 hours      0.0.0.0:8000->80/tcp, [::]:8000->80/tcp                         signet-client1\\ne37bd4bdecbc   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-server:v-99            \"java -jar app.jar\"      2 hours ago      Up 2 hours      0.0.0.0:8002->8080/tcp, [::]:8002->8080/tcp                     signet-server\\n04bba3a327f7   511662517913.dkr.ecr.ap-northeast-2.amazonaws.com/signet/signet-system:v-10            \"java -jar app.jar\"      2 hours ago      Up 2 hours      0.0.0.0:8003->8080/tcp, [::]:8003->8080/tcp                     signet-system\\nc1b563a0c350   bitnami/postgresql-repmgr:latest                                                       \"/opt/bitnami/script…\"   18 hours ago     Up 3 hours                                                                      pg-1\\nfe3bcafcfbcf   apache/kafka:latest                                                                    \"/__cacert_entrypoin…\"   7 days ago       Up 4 days       0.0.0.0:9092-9094->9092-9094/tcp, :::9092-9094->9092-9094/tcp   kafka-2\\nkcl@kcl-2:~/installation/5.subscriber$\\n```\\n\\nServer-3 \\n\\n다음 2개의 instance(pgp1, kafka-3)와 haproxy가 정상작동하여야 합니다.\\n\\n```bash\\ncl@kcl-dev:~$ docker ps\\nCONTAINER ID   IMAGE                   COMMAND                  CREATED       STATUS       PORTS\\n                                      NAMES\\ndea7dbec4a00   bitnami/pgpool:latest   \"/opt/bitnami/script…\"   2 hours ago   Up 2 hours\\n                                      pgp1\\n61fc10a48541   apache/kafka:latest     \"/__cacert_entrypoin…\"   7 days ago    Up 4 days    0.0.0.0:9092-9094->9092-9094/tcp, :::9092-9094->9092-9094/tcp   kafka-3\\n\\nkcl@kcl-dev:~$ sudo systemctl status haproxy.service\\n● haproxy.service - HAProxy Load Balancer\\n     Loaded: loaded (/usr/lib/systemd/system/haproxy.service; enabled; preset: enabled)\\n     Active: active (running) since Wed 2025-01-15 03:59:39 UTC; 2s ago\\n       Docs: man:haproxy(1)\\n             file:/usr/share/doc/haproxy/configuration.txt.gz\\n   Main PID: 29417 (haproxy)\\n     Status: \"Ready.\"\\n      Tasks: 17 (limit: 38049)\\n     Memory: 43.7M (peak: 45.6M)\\n        CPU: 89ms\\n     CGroup: /system.slice/haproxy.service\\n             ├─29417 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.so>\\n             └─29419 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -S /run/haproxy-master.so>\\n\\nJan 15 03:59:39 kcl-dev systemd[1]: Starting haproxy.service - HAProxy Load Balancer...\\nJan 15 03:59:39 kcl-dev haproxy[29417]: [NOTICE]   (29417) : New worker (29419) forked\\nJan 15 03:59:39 kcl-dev haproxy[29417]: [NOTICE]   (29417) : Loading success.\\nJan 15 03:59:39 kcl-dev systemd[1]: Started haproxy.service - HAProxy Load Balancer.\\n```\\n\\n\\n1. docker container 가 이미 사용중인 경우\\n\\n```bash\\ndocker: Error response from daemon: Conflict. The container name \"/pg-1\" is already in use by container \"50e98d1b0d083354704640babc6686b848cfc327560fb0106156e6c90def1cbf\". You have to remove (or rename) that container to be able to reuse that name.\\n```\\ndocker를 실행하다 다음과 같은 메시지가 나오면, 해당 이름이 사용중이므로 container(위의 경우에는 `pg-1`)을 제거하고 다시 실행합니다.\\n제거하는 방법은\\n\\n```bash\\ndocker rm pg-1\\n```\\n\\n입니다.\\n\\n\\n- Web Browser 접속이 되지 않는 경우\\n\\n```bash\\ndocker logs -f -n 1000 [instance name] \\n```\\n\\n을 실행하여 로그를 확인합니다. 로그의 해석이 불가능할 경우, 이를 캡춰해 개발사에 전달해 주세요.\\n(server1, server2의 signet-server,signet-system 에 대하여 로그를 각각 캡춰필요)\\n\\n- Data 가 들어오지 않는 경우\\n\\n먼저 server1 의 kafka-subscriber의 로그에서 데이타가 정상적으로 들어오는지 확인합니다. \\n```bash\\ndocker logs -f -n 1000 kafka-subscriber\\nCommand CHAMINFO received.\\nChamber status : 2 rows inserted, 2 reported\\n2025-01-15T03:42:21.570858090\\nCommand MODINFO received.\\n.\\n. 생략\\n.\\nTask ID: 10018__2025-01-10T01:51:55Z\\nTask ID: 10018__2025-01-10T01:51:55Z\\nCycler status : 8 rows inserted, 8 reported\\nNo is_parallel, Status -> Satus, TaskName as testname?\\n```\\n\\n위와 같이 데이타가 들어오는 과정이 보이지 않을 경우, kafka-subscriber 가 실행중인지 확인합니다.\\n```bash\\ndocker ps -a | grep kafka-subscriber\\n```\\n\\n만약 결과가 보이지 않으면 kafka-subscriber를 재시동 해봅니다.\\n```bash\\ndocker restart kafka-subscriber\\n```\\n\\n\\n## 서버별 실행 스크립트\\n\\n### Server 1 (~/installation/)\\n\\n.                                                                                \\n├── 1.prerequisite                                                               \\n│\\xa0\\xa0 └── install-docker.sh # 도커설치                                                       \\n├── 2.postgresql                                                                 \\n│\\xa0\\xa0 ├── run-as-active.sh  # Postgresql 실행 (Active)                                                       \\n│\\xa0\\xa0 └── run-as-standby.sh # Postgresql 실행 (Standby)                                                                  \\n├── 3.kafka                                                                      \\n│\\xa0\\xa0 └── run-kafka.sh  # 카프카 실행                                                           \\n├── 4.application                                                                \\n│\\xa0\\xa0 ├── check-version-client.sh # signet-client 버전체크(점검용)                                               \\n│\\xa0\\xa0 ├── check-version-server.sh # signet-server 버전체크(점검용)\\n│\\xa0\\xa0 ├── check-version-system.sh # signet-system 버전체크(점검용)                                                \\n│\\xa0\\xa0 └── run-server.sh  # Bife Cycler Application 실행                                                          \\n└── 5.subscriber                                                                 \\n    └── kafka-client.sh # Kafka subscriber 실행                                                         \\n\\n### Server 2 (~/installation/)\\n\\n.                                                                                \\n├── 1.prerequisite                                                               \\n│\\xa0\\xa0 └── install-docker.sh # 도커설치                                                       \\n├── 2.postgresql                                                                 \\n│\\xa0\\xa0 ├── run-as-active.sh  # Postgresql 실행 (Active)                                                       \\n│\\xa0\\xa0 └── run-as-standby.sh # Postgresql 실행 (Standby)                                                                  \\n├── 3.kafka                                                                      \\n│\\xa0\\xa0 └── run-kafka.sh  # 카프카 실행                                                           \\n├── 4.application                                                                \\n│\\xa0\\xa0 ├── check-version-client.sh # signet-client 버전체크(점검용)                                               \\n│\\xa0\\xa0 ├── check-version-server.sh # signet-server 버전체크(점검용)\\n│\\xa0\\xa0 ├── check-version-system.sh # signet-system 버전체크(점검용)                                                \\n│\\xa0\\xa0 └── run-server.sh  # Bife Cycler Application 실행                                                          \\n└── 5.subscriber                                                                 \\n    └── kafka-client.sh # Kafka subscriber 실행                                                         \\n                                                         \\n\\n### Server 3 (~/installation/)\\n.\\n├── 1.prerequisite\\n│\\xa0\\xa0 └── install-docker.sh # 도커설치\\n├── 2.postgresql\\n│\\xa0\\xa0 └── pgp.sh # postgresql pgpool-II 설치(monitoring)\\n└── 4.kafka\\n    └── run-kafka-3.sh (Kafka Client)   ')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"How to install bife-cycler?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 체인 정의\n",
    "rag_chain = (\n",
    "    # 검색 결과를 포맷팅하고 질문을 처리합니다.\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt  # 프롬프트를 적용합니다.\n",
    "    | model  # 모델을 적용합니다.\n",
    "    | StrOutputParser()  # 문자열 출력 파서를 적용합니다.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Docker 컨테이너가 이미 사용 중인 경우, 해당 이름을 재사용하기 위해선 컨테이너를 제거하거나 이름을 변경해야 합니다.\\n\\n1. **컨테이너 제거 방법**:\\n   ```bash\\ndocker rm [컨테이너 이름]\\n```\\n   예시: `docker rm pg-1`\\n\\n2. **웹 브라우저 접속 오류 발생 시**:\\n   - 로그 확인 명령어:\\n     ```bash\\ndocker logs -f -n 1000 [인스턴스 이름]\\n```\\n     (예: server1, server2의 signet-server, signet-system에 대해 각각 로그 캡처 필요)\\n\\n3. **데이터가 들어오지 않는 경우**:\\n   - `kafka-subscriber`의 로그에서 데이터 수신 확인\\n   ```bash\\ndocker logs -f -n 1000 kafka-subscriber\\n```\\n   - `kafka-subscriber`가 실행 중인지 확인\\n   ```bash\\ndocker ps -a | grep kafka-subscriber\\n```\\n   - 재시동 필요할 경우:\\n     ```bash\\ndocker restart kafka-subscriber\\n```\\n\\n서버별 실행 스크립트는 다음과 같이 구성됩니다.\\n\\n### Server 1 (~/installation/)\\n- `1.prerequisite`: 도커 설치 스크립트 (`install-docker.sh`)\\n- `2.postgresql`: PostgreSQL 실행 관련 스크립트 (`run-as-active.sh` 및 `run-as-standby.sh`)\\n- `3.kafka`: 카프카 실행 스크립트 (`run-kafka.sh`)\\n- `4.application`: 애플리케이션 실행 및 버전 체크 관련 스크립트 (`run-server.sh`, `check-version-client.sh`, `check-version-server.sh`, `check-version-system.sh`)\\n- `5.subscriber`: 카프카 서브스크라이버 실행 스크립트 (`kafka-client.sh`)\\n\\n### Server 2 (~/installation/)\\n- 구성은 Server 1과 동일합니다.\\n\\n### Server 3 (~/installation/)\\n- `1.prerequisite`: 도커 설치 스크립트 (`install-docker.sh`)\\n- `2.postgresql`: PostgreSQL pgpool-II 설치 스크립트 (`pgp.sh`) - 모니터링용\\n- `4.kafka`: 카프카 클라이언트 실행 스크립트 (`run-kafka-3.sh`)\\n\\n이러한 설정을 통해 각 서버에서 필요한 서비스를 관리하고, 발생하는 오류에 대한 대응 방법을 확인할 수 있습니다.'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"bife-cycler 설치하는 방법을 순서대로 알려줘.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker container 가 이미 사용중인 경우의 해결 방법과 서버별 실행 스크립트에 대한 정보를 제공했습니다. 도커 컨테이너 이름 충돌 시 제거하는 방법과, 로그 확인 및 데이터 들어오지 않는 경우의 처리 방안을 설명하였습니다. 또한 각 서버에서 실행해야 할 스크립트에 대한 구조와 파일 목록을 제공하였습니다."
     ]
    }
   ],
   "source": [
    "for token in rag_chain.stream(\"bife-cycler 설치하는 방법을 순서대로 알려줘. 서버정보를 먼저 보여줘. 내용은 아주 상세하게 markdown으로 한글로 작성해줘. \"):\n",
    "    # print(token.content, end=\"\")\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It appears you've provided a detailed guide on troubleshooting and running Docker containers for a specific application, likely related to Bife Cycler. The steps include checking if a container is already in use, removing it if necessary, and then proceeding with the execution of various scripts tailored for different servers (Server 1, Server 2, and Server 3) within the `~/installation/` directory. Each server has its set of scripts designed to install Docker, run PostgreSQL, Kafka, and other application components.\n",
      "\n",
      "To address potential issues or questions you might have based on this information:\n",
      "\n",
      "1. **Container Name Conflict**: If you encounter an error due to a container name conflict (e.g., `pg-1` is already in use), you can remove the existing container using `docker rm pg-1`. Then, you should be able to run your Docker command again without the conflict.\n",
      "\n",
      "2. **Web Browser Access Issues**: For troubleshooting web browser access problems, checking the logs of the relevant containers (e.g., `signet-server`, `signet-system`) can provide insights into what might be going wrong. You can use `docker logs -f -n 1000 [instance name]` for this purpose.\n",
      "\n",
      "3. **Data Not Being Received**: If data isn't being received as expected, first verify that the Kafka subscriber is receiving data by checking its logs (`docker logs -f -n 1000 kafka-subscriber`). Ensure the `kafka-subscriber` container is running; if not, restart it with `docker restart kafka-subscriber`.\n",
      "\n",
      "4. **Server-Specific Scripts**: The directory structure suggests a specific set of scripts for each server:\n",
      "   - **Server 1 & Server 2** have scripts for installing Docker, setting up PostgreSQL (both as active and standby), running Kafka, checking versions of `signet-client`, `signet-server`, and `signet-system`, running the Bife Cycler application, and a Kafka client.\n",
      "   - **Server 3** has scripts focused on installing Docker and setting up PostgreSQL with pgpool-II for monitoring, along with a script for running Kafka.\n",
      "\n",
      "To ensure smooth operation:\n",
      "- Always check container statuses and logs when encountering issues.\n",
      "- Verify that all required containers are running before attempting to access the application or data.\n",
      "- Use `docker ps -a` to list all containers (running and stopped) and `docker logs` for troubleshooting.\n",
      "\n",
      "If you have a specific question about these scripts, the Docker containers, or the application itself, please provide more details so I can offer a more tailored response."
     ]
    }
   ],
   "source": [
    "for token in rag_chain.stream(\"bife-cycler에서 kafka를 설정하는 방법을 알려줘. 내용은 아주 상세하게 markdown으로 한글로 작성해줘. \"):\n",
    "    # print(token.content, end=\"\")\n",
    "    print(token, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
